{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2fbf0ba-a34a-4eda-86ad-ae2894ff0c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-19 14:08:14.016660: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1630, 20, 5)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (2,5) into shape (20,5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 274\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;66;03m# 调用类中的方法，处理原始数据\u001b[39;00m\n\u001b[1;32m    273\u001b[0m DM \u001b[38;5;241m=\u001b[39m origin_data_maker\n\u001b[0;32m--> 274\u001b[0m daily_train \u001b[38;5;241m=\u001b[39m \u001b[43mDM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdaily_train_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdaily_train_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    275\u001b[0m daily_test \u001b[38;5;241m=\u001b[39m DM\u001b[38;5;241m.\u001b[39mdaily_test_data(daily_test_df)\n\u001b[1;32m    276\u001b[0m fif_train \u001b[38;5;241m=\u001b[39m DM\u001b[38;5;241m.\u001b[39mfif_train_data(fif_train_df)\n",
      "Cell \u001b[0;32mIn[1], line 55\u001b[0m, in \u001b[0;36mData_maker.daily_train_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28mprint\u001b[39m(samples\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m rows:\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;66;03m### 每一个填入用于预测一天的开盘价到波动率矩阵\u001b[39;00m\n\u001b[0;32m---> 55\u001b[0m     samples[j] \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mloc[\n\u001b[1;32m     56\u001b[0m                       (data\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m j) \u001b[38;5;241m&\u001b[39m (data\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdaily_back \u001b[38;5;241m+\u001b[39m j),\n\u001b[1;32m     57\u001b[0m                       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopen\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvolume_rate\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28mprint\u001b[39m(data\u001b[38;5;241m.\u001b[39mindex)\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m日频训练array：\u001b[39m\u001b[38;5;124m'\u001b[39m,samples\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (2,5) into shape (20,5)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import keras\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.models import Model\n",
    "from keras import layers\n",
    "from keras import Input\n",
    "from sklearn.metrics import confusion_matrix,roc_curve, auc,recall_score,precision_score,f1_score\n",
    "\n",
    "\n",
    "\n",
    "#参数设置\n",
    "\n",
    "# plt.rcParams['font.sans-serif'] = ['SimHei'] # 指定默认字体\n",
    "# plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "\n",
    "# from tensorflow import losses\n",
    "\n",
    "wenben_back=20\n",
    "total_day=2062\n",
    "train_num=1650\n",
    "\n",
    "long_term_back=20\n",
    "short_term_back=2\n",
    "\n",
    "wenben_sort=2\n",
    "batch_size=8\n",
    "epochs=20\n",
    "LSTM_num=100\n",
    "dense_num=20\n",
    "\n",
    "\n",
    "mix_file='777888.xlsx'\n",
    "first_columns='search_index'\n",
    "\n",
    "\n",
    "\n",
    "test_num=total_day-train_num\n",
    "\n",
    "# 数据转换类，返回多个字典？\n",
    "\n",
    "class Data_maker:\n",
    "    def __init__(self,train_num,test_num,fif_back,daily_back,wenben_back,long_term_back,short_term_back):\n",
    "        self.train_num=train_num\n",
    "        self.test_num=test_num\n",
    "        self.fif_back=fif_back\n",
    "        self.daily_back=daily_back\n",
    "        self.wenben_back = wenben_back\n",
    "        self.long_term_back=long_term_back\n",
    "        self.short_term_back = short_term_back\n",
    "\n",
    "    def daily_train_data(self,data):\n",
    "        while True:\n",
    "            rows = list(range(self.train_num - self.wenben_back)) #总共1650个数据，由于扣除前面20个数据，所以为1630\n",
    "            ### 先构造空（预测日长度*日后移）array\n",
    "            samples = np.zeros((len(rows),\n",
    "                                 self.daily_back,\n",
    "                                 5))\n",
    "            print(samples.shape)\n",
    "            for j in rows:\n",
    "                ### 每一个填入用于预测一天的开盘价到波动率矩阵\n",
    "                samples[j] = data.loc[\n",
    "                                  (data.index >= j) & (data.index < self.daily_back + j),\n",
    "                                  'open':'volume_rate']\n",
    "            print(data.index)\n",
    "            print('日频训练array：',samples.shape)\n",
    "            return samples\n",
    "    def fif_train_data(self,data):\n",
    "        while True:\n",
    "            rows = list(range(self.train_num - self.wenben_back))\n",
    "            samples = np.zeros((len(rows),\n",
    "                                 self.fif_back,\n",
    "                                 5))\n",
    "            for j in rows:\n",
    "\n",
    "                samples[j] = data.loc[\n",
    "                              (data.index >= j * self.fif_back ) & (data.index < (j+1) * self.fif_back),\n",
    "                              'open':]\n",
    "            print('十五分钟训练array：',samples.shape)\n",
    "            return samples\n",
    "    def wenben_long_term_train_data(self,data):\n",
    "        while True:\n",
    "            rows = list(range(self.train_num - self.wenben_back)) #总共1489个数据，由于扣除前面20个数据，所以为1469\n",
    "            samples = np.zeros((len(rows),\n",
    "                                 self.long_term_back,\n",
    "                                 wenben_sort))\n",
    "            for j in rows:\n",
    "\n",
    "                samples[j] = data.loc[\n",
    "                                  (data.index >= j) & (data.index < self.long_term_back + j),\n",
    "                                  first_columns:]\n",
    "            print('文本长期训练array：',samples.shape)\n",
    "            return samples\n",
    "    def wenben_short_term_train_data(self,data):\n",
    "        while True:\n",
    "            rows = list(range(self.train_num - self.wenben_back)) #总共1489个数据，由于扣除前面20个数据，所以为1469\n",
    "            samples = np.zeros((len(rows),\n",
    "                                 self.short_term_back,\n",
    "                                wenben_sort))\n",
    "            for j in rows:\n",
    "\n",
    "                samples[j] = data.loc[\n",
    "                                  (data.index >= j) & (data.index < self.short_term_back + j),\n",
    "                                  first_columns:]\n",
    "            print('文本短期训练array：',samples.shape)\n",
    "            return samples\n",
    "    def daily_test_data(self,data):\n",
    "        while True:\n",
    "            rows = list(range(self.test_num - self.wenben_back))\n",
    "            print(self.test_num,self.wenben_back)\n",
    "            print(rows)\n",
    "            samples = np.zeros((len(rows),\n",
    "                                self.daily_back,\n",
    "                                 5))\n",
    "            for j in rows:\n",
    "\n",
    "\n",
    "                samples[j] = data.loc[\n",
    "                                  (data.index >= self.train_num+j) & (data.index < self.train_num+self.daily_back + j),\n",
    "                                  'open':'volume_rate']\n",
    "            print('日测试array：',samples.shape)\n",
    "            print('试一试index', data.index,'train_num',self.train_num)\n",
    "            return samples\n",
    "\n",
    "    def wenben_long_term_test_data(self, data):\n",
    "        while True:\n",
    "            rows = list(range(self.test_num - self.wenben_back))\n",
    "            samples = np.zeros((len(rows),\n",
    "                                self.long_term_back,\n",
    "                                wenben_sort))\n",
    "            for j in rows:\n",
    "                samples[j] = data.loc[\n",
    "                             (data.index >= self.train_num + j) & (data.index < self.train_num + self.long_term_back + j),\n",
    "                             first_columns:]\n",
    "            print('长期文本测试array：', samples.shape)\n",
    "            return samples\n",
    "    def wenben_short_term_test_data(self, data):\n",
    "        while True:\n",
    "            rows = list(range(self.test_num - self.wenben_back))\n",
    "            samples = np.zeros((len(rows),\n",
    "                                self.short_term_back,\n",
    "                                wenben_sort))\n",
    "            for j in rows:\n",
    "                samples[j] = data.loc[\n",
    "                             (data.index >= self.train_num + j) & (data.index < self.train_num + self.short_term_back + j),\n",
    "                             first_columns:]\n",
    "            print('短期文本测试array：', samples.shape)\n",
    "            return samples\n",
    "    def fif_test_data(self,data):\n",
    "        while True:\n",
    "            rows = list(range(self.test_num - self.wenben_back))\n",
    "            samples = np.zeros((len(rows),\n",
    "                                self.fif_back,\n",
    "                                 5))\n",
    "            for j in rows:\n",
    "\n",
    "\n",
    "                samples[j] = data.loc[\n",
    "                                 (data.index >= 16*self.train_num+(j) * self.fif_back) & (data.index < 16*self.train_num+(j+1) * self.fif_back),\n",
    "                                 'open':]\n",
    "            print('十五分钟测试array：',samples.shape)\n",
    "            return samples\n",
    "    def target_train_data(self,data):\n",
    "        while True:\n",
    "            rows = list(range(self.train_num-self.wenben_back))\n",
    "            targets = np.zeros((len(rows),))\n",
    "            for j in rows:\n",
    "\n",
    "\n",
    "                targets[j] = data.loc[data.index == j, 'target']\n",
    "            print('训练标签array',targets.shape)\n",
    "            return targets\n",
    "    def target_test_data(self,data):\n",
    "        while True:\n",
    "            rows = list(range(self.test_num-self.wenben_back))\n",
    "            targets = np.zeros((len(rows),))\n",
    "            for j in rows:\n",
    "\n",
    "\n",
    "                targets[j] = data.loc[data.index == self.train_num+j, 'target'] ##出问题：应该是。而不是***：data.index == self.train_num+j\n",
    "            print(targets.shape)\n",
    "            return targets\n",
    "\n",
    "# 设置类方法里的参数，赋值给origin_data_maker，仍然是一个class类\n",
    "\n",
    "origin_data_maker=Data_maker(train_num=train_num,test_num=test_num,fif_back=16,daily_back=20,wenben_back=wenben_back,long_term_back=long_term_back,short_term_back=short_term_back)\n",
    "\n",
    "# 读取原始数据\n",
    "new_dir='/Users/ccmac/Documents/毕业论文数据/数据二合为一'\n",
    "dir='/Users/ccmac/Documents/毕业论文数据/数据区间试验'\n",
    "# wenben_dir='/Users/ccmac/Documents/毕业论文数据/每日均值'\n",
    "daily_df=pd.read_excel(os.path.join(new_dir,mix_file))\n",
    "fif_df=pd.read_excel(os.path.join(dir,'fif_data.xlsx'))\n",
    "target_df=pd.read_excel(os.path.join(dir,'target.xlsx'))\n",
    "wenben_df=pd.read_excel(os.path.join(new_dir,mix_file))\n",
    "\n",
    "# 历史数据标准化函数norm\n",
    "\n",
    "def norm(df):\n",
    "    x=df.copy()\n",
    "    open_mean_value = df['open'].mean(axis=0)\n",
    "    high_mean_value = df['high'].mean(axis=0)\n",
    "    low_mean_value = df['low'].mean()\n",
    "    close_mean_value = df['close'].mean()\n",
    "    volumerate_mean_value = df['volume_rate'].mean()\n",
    "\n",
    "    open_std_value = df['open'].std()\n",
    "    high_std_value = df['high'].std()\n",
    "    low_std_value = df['low'].std()\n",
    "    close_std_value = df['close'].std()\n",
    "    volumerate_std_value = df['volume_rate'].std()\n",
    "\n",
    "    x['open']=(df['open']-open_mean_value)/open_std_value\n",
    "    x['high'] = (df['high'] - high_mean_value) / high_std_value\n",
    "    x['low'] =  (df['low'] - low_mean_value) / low_std_value\n",
    "    x['close'] =  (df['close'] - close_mean_value) / close_std_value\n",
    "    x['volume_rate'] = (df['volume_rate'] - volumerate_mean_value) / volumerate_std_value\n",
    "    df=x\n",
    "    return df\n",
    "\n",
    "# 文本数据标准化函数wenben_norm\n",
    "\n",
    "def wenben_norm(df):\n",
    "    x=df.copy()\n",
    "    sector_score_mean_value = df['sector_score'].mean(axis=0)\n",
    "    search_index_mean_value = df['search_index'].mean(axis=0)\n",
    "    # media_attention_mean_value = df['media_attention'].mean(axis=0)\n",
    "\n",
    "\n",
    "    sector_score_std_value = df['sector_score'].std()\n",
    "    search_index_std_value = df['search_index'].std()\n",
    "    # media_attention_std_value = df['media_attention'].std()\n",
    "\n",
    "\n",
    "    x['sector_score']=(df['sector_score']-sector_score_mean_value)/sector_score_std_value\n",
    "    x['search_index'] = (df['search_index'] - search_index_mean_value) / search_index_std_value\n",
    "    # x['media_attention'] = (df['media_attention'] - media_attention_mean_value) / media_attention_std_value\n",
    "\n",
    "    df=x\n",
    "    return df\n",
    "\n",
    "# 数据切分\n",
    "\n",
    "def split_data(train_num=train_num,wenben_back=wenben_back):\n",
    "    daily_train_df=daily_df.loc[daily_df.index<train_num]\n",
    "    daily_test_df=daily_df.loc[daily_df.index>=train_num]\n",
    "    fif_train_df=fif_df.loc[fif_df.index<16*train_num]\n",
    "    fif_test_df=fif_df.loc[fif_df.index>=16*train_num]\n",
    "    wenben_train_df=wenben_df.loc[wenben_df.index<train_num]\n",
    "    wenben_test_df=wenben_df.loc[wenben_df.index>=train_num]\n",
    "\n",
    "    target_train_df=target_df.loc[target_df.index<train_num]\n",
    "    target_test_df=target_df.loc[target_df.index>=train_num]\n",
    "\n",
    "    daily_train_df=norm(daily_train_df)\n",
    "    daily_test_df=norm(daily_test_df)\n",
    "    fif_train_df=norm(fif_train_df)\n",
    "    fif_test_df=norm(fif_test_df)\n",
    "    wenben_train_df=wenben_norm(wenben_train_df)\n",
    "    wenben_test_df = wenben_norm(wenben_test_df)\n",
    "\n",
    "\n",
    "    return {'daily_train_df':daily_train_df,\n",
    "            'daily_test_df':daily_test_df,\n",
    "            'fif_train_df':fif_train_df,\n",
    "            'fif_test_df':fif_test_df,\n",
    "            'target_train_df':target_train_df,\n",
    "            'target_test_df':target_test_df,\n",
    "            'wenben_train_df':wenben_train_df,\n",
    "            'wenben_test_df': wenben_test_df\n",
    "            }\n",
    "\n",
    "# 进行数据切分\n",
    "\n",
    "daily_train_df=split_data()['daily_train_df']\n",
    "print('日频训练切分：',daily_train_df.shape)\n",
    "daily_test_df=split_data()['daily_test_df']\n",
    "print('日频测试切分：',daily_test_df.shape)\n",
    "fif_train_df=split_data()['fif_train_df']\n",
    "print('十五分钟频训练切分：',fif_train_df.shape)\n",
    "fif_test_df=split_data()['fif_test_df']\n",
    "print('十五分钟频测试切分：',fif_test_df.shape)\n",
    "target_train_df=split_data()['target_train_df']\n",
    "print('训练目标切分：',target_train_df.shape)\n",
    "target_test_df=split_data()['target_test_df']\n",
    "print('测试目标切分：',target_test_df.shape)\n",
    "wenben_norm_train_df=split_data()['wenben_train_df']\n",
    "wenben_norm_test_df=split_data()['wenben_test_df']\n",
    "\n",
    "# 调用类中的方法,处理原始数据\n",
    "\n",
    "DM=origin_data_maker\n",
    "\n",
    "daily_train=DM.daily_train_data(daily_train_df)\n",
    "daily_test=DM.daily_test_data(daily_test_df)\n",
    "fif_train=DM.fif_train_data(fif_train_df)\n",
    "fif_test=DM.fif_test_data(fif_test_df)\n",
    "target_train=DM.target_train_data(target_train_df)\n",
    "target_test=DM.target_test_data(target_test_df)\n",
    "\n",
    "wenben_long_term_train=DM.wenben_long_term_train_data(wenben_norm_train_df)\n",
    "wenben_short_term_train=DM.wenben_short_term_train_data(wenben_norm_train_df)\n",
    "wenben_long_term_test=DM.wenben_long_term_test_data(wenben_norm_test_df)\n",
    "wenben_short_term_test=DM.wenben_short_term_test_data(wenben_norm_test_df)\n",
    "\n",
    "# 构建神经网络模型\n",
    "\n",
    "def my_model(long_term_back,short_term_back,wenben_sort):\n",
    "\n",
    "    ##### 一、模型搭建\n",
    "\n",
    "    # 文本输入训练(!!!卷积滤镜行列先后)\n",
    "    wenben_long_term_input=Input(shape=(long_term_back,wenben_sort),dtype='float32',name='wenben_long_term_input')\n",
    "    Conv1D_fif=layers.Conv1D(16,1,strides=1)(wenben_long_term_input)\n",
    "    LSTM_long_term=layers.LSTM(LSTM_num)(Conv1D_fif)\n",
    "    wenben_short_term_input = Input(shape=(short_term_back,wenben_sort), dtype='float32', name='wenben_short_term_input')\n",
    "    Conv1D_fif = layers.Conv1D(16, 1, strides=1)(wenben_short_term_input)\n",
    "    LSTM_short_term = layers.LSTM(LSTM_num)(Conv1D_fif)\n",
    "    # 15分钟频输入训练(!!!卷积滤镜行列先后)\n",
    "    fif_min_input=Input(shape=(16,5),dtype='float32',name='fif_min_input')\n",
    "    # fif_min_input=(8,16,4,1)\n",
    "    Conv1D_fif=layers.Conv1D(16,1,strides=1)(fif_min_input)\n",
    "    LSTM_fif=layers.LSTM(LSTM_num)(Conv1D_fif)\n",
    "\n",
    "    # 日频输入训练\n",
    "    daily_input=Input(shape=(20,5),dtype='float32',name='daily_input')\n",
    "    # daily_input=(8,16,4,1)\n",
    "    Conv1D_daily=layers.Conv1D(16,1,strides=1)(daily_input)\n",
    "    LSTM_daily=layers.LSTM(LSTM_num)(Conv1D_daily)\n",
    "    # 15分钟频训练结果和日频训练结果合并\n",
    "    concatenated=layers.concatenate([LSTM_fif,LSTM_daily,LSTM_long_term,LSTM_short_term],axis=-1) # axis=-1按照最后一个轴粘合\n",
    "\n",
    "    alloy=layers.Dense(dense_num,activation='relu')(concatenated) #将粘合结果再接一个全连接层\n",
    "    dropout=layers.Dropout(0.2)(alloy)\n",
    "    output=layers.Dense(1,activation='sigmoid')(dropout)\n",
    "    model=Model([fif_min_input,daily_input,wenben_long_term_input,wenben_short_term_input],output) #八股文：将输入和输出圈起来\n",
    "\n",
    "    print(model.summary())\n",
    "    model.compile(optimizer=keras.optimizers.Adam(lr=1e-3),loss='binary_crossentropy',metrics=['acc'])\n",
    "    return model\n",
    "    # reduce_lr = ReduceLROnPlateau(monitor='val_loss', patience=5, mode='auto')\n",
    "\n",
    "\n",
    "# 模型滞后时长赋值\n",
    "\n",
    "model=my_model(long_term_back=long_term_back,short_term_back=short_term_back,wenben_sort=wenben_sort)\n",
    "\n",
    "# model.fit(输入自变量x，因变量y)\n",
    "history=model.fit(x=[fif_train,daily_train,wenben_long_term_train,wenben_short_term_train],y=target_train,batch_size=batch_size,validation_split=0.25,epochs=epochs)\n",
    "\n",
    "# model.evaluate(输入测试数据)，进行模型预测性能测试\n",
    "\n",
    "loss,accuracy = model.evaluate([fif_test,daily_test,wenben_long_term_test,wenben_short_term_test],y=target_test)\n",
    "print(loss,accuracy)\n",
    "# 构建y的函数\n",
    "\n",
    "def gen_y_pred():\n",
    "    y_predict=model.predict([fif_test,daily_test,wenben_long_term_test,wenben_short_term_test],batch_size=1).reshape(test_num-wenben_back).tolist() ###batch_size要设为1，不然evaluate和predict结果不同\n",
    "    y_pred=[]\n",
    "    for i,v in enumerate(y_predict):\n",
    "        if v>0.5:\n",
    "            y_pred.append(1)\n",
    "        if v<0.5:\n",
    "            y_pred.append(0)\n",
    "    return y_pred\n",
    "\n",
    "# 制作y\n",
    "\n",
    "y_pred=gen_y_pred()\n",
    "print(y_pred)\n",
    "\n",
    "#  构建使用测试集作为回测数据的类\n",
    "class Back_tes_trader:\n",
    "    def __init__(self,train_num,daily_back,wenben_back):\n",
    "        self.train_num=train_num\n",
    "        self.daily_back=daily_back\n",
    "        self.wenben_back = wenben_back\n",
    "    def daily_test_data(self,data):\n",
    "        while True:\n",
    "            samples = data.loc[\n",
    "                data.index >=self.train_num+self.wenben_back ,\n",
    "                ['open','close']]\n",
    "            print(data.index)\n",
    "            return samples\n",
    "        \n",
    "\n",
    "# 回测数据集代入参数，形成回撤数据back_tes_trader\n",
    "back_tes_trader=Back_tes_trader(train_num=train_num,daily_back=20,wenben_back=wenben_back)\n",
    "\n",
    "\n",
    "def split_back_trader(train_num=train_num):\n",
    "\n",
    "    daily_test_df=daily_df.loc[daily_df.index>=train_num]\n",
    "\n",
    "    return {'daily_test_df':daily_test_df}\n",
    "\n",
    "\n",
    "back_df=split_back_trader()['daily_test_df']\n",
    "\n",
    "back_df\n",
    "\n",
    "backtrader_df=back_tes_trader.daily_test_data(back_df)\n",
    "\n",
    "# 形成day_rate_of_return日内收益率，和rate_of_return隔夜收益率\n",
    "\n",
    "backtrader_df['rate_of_return'] = backtrader_df['close'].rolling(2).apply(lambda x: x[1] / x[0] - 1, raw=True)\n",
    "backtrader_df['day_rate_of_return']=backtrader_df['close']/backtrader_df['open']-1\n",
    "\n",
    "clo_1=backtrader_df.loc[(backtrader_df.index<total_day-1),\"close\"].tolist()\n",
    "\n",
    "print(len(clo_1))\n",
    "print(backtrader_df.loc[(backtrader_df.index>=train_num+20+1),:])\n",
    "backtrader_df.loc[(backtrader_df.index>=train_num+20+1),'last_close']=clo_1\n",
    "backtrader_df['sale_rate_of_return']=backtrader_df['open']/backtrader_df['last_close']-1\n",
    "\n",
    "\n",
    "print(backtrader_df)\n",
    "print(backtrader_df.shape)\n",
    "trade_day_return_list=[]\n",
    "return_list=[]\n",
    "every_day_return_list=[]\n",
    "\n",
    "# 回测交易逻辑\n",
    "\n",
    "def backtrader(list,df):\n",
    "    a=0\n",
    "\n",
    "    rate_of_return = 1\n",
    "    for i,v in enumerate(list):\n",
    "        if (v ==1)&(a==0):\n",
    "            b=(1 + df.loc[train_num+20 + i, 'day_rate_of_return'])\n",
    "            rate_of_return= rate_of_return * b\n",
    "            a=1\n",
    "            trade_day_return_list.append(b-1)\n",
    "            return_list.append(rate_of_return)\n",
    "            every_day_return_list.append(b - 1)\n",
    "\n",
    "        elif (v ==1)&(a==1):\n",
    "            b=(1 + df.loc[train_num+20 + i, 'rate_of_return'])\n",
    "            rate_of_return= rate_of_return *b\n",
    "            a=a\n",
    "            trade_day_return_list.append(b-1)\n",
    "            return_list.append(rate_of_return)\n",
    "            every_day_return_list.append(b - 1)\n",
    "        elif (v==0)&(a==0):\n",
    "            rate_of_return=rate_of_return\n",
    "            a=a\n",
    "            every_day_return_list.append(0)\n",
    "\n",
    "        elif (v==0)&(a==1):\n",
    "            a=0\n",
    "            b = (1 + df.loc[train_num+20 + i, 'sale_rate_of_return'])\n",
    "            rate_of_return=rate_of_return*b\n",
    "            trade_day_return_list.append(b-1)\n",
    "            every_day_return_list.append(b - 1)\n",
    "            return_list.append(rate_of_return)\n",
    "    return a,trade_day_return_list,rate_of_return,return_list,every_day_return_list\n",
    "\n",
    "\n",
    "result=backtrader(y_pred,backtrader_df)\n",
    "print(result[1])\n",
    "print(result[2])\n",
    "print(result[3])\n",
    "pingjun_nian_jiaoyi_ri=240*len(result[1])/(len(y_pred))\n",
    "sharp=(np.mean(result[1]))/(np.std(result[1],ddof=1))*np.sqrt(pingjun_nian_jiaoyi_ri)\n",
    "# sharp1=(np.mean(result[4]))/(np.std(result[4]))\n",
    "# print('夏普比率--：',sharp1)\n",
    "print('夏普比率：',sharp)\n",
    "print('收益率：',result[2]-1)\n",
    "\n",
    "\n",
    "returns=result[3]\n",
    "returns = [ret - 1 for ret in returns]\n",
    "returns\n",
    "\n",
    "\n",
    "\n",
    "returns=result[3]\n",
    "returns = [ret - 1 for ret in returns]\n",
    "\n",
    "# 将收益率列表转换为pandas的Series对象，方便处理\n",
    "returns_series = pd.Series(returns)\n",
    "\n",
    "# 计算累计收益率\n",
    "cumulative_returns = (1 + returns_series).cumprod() - 1\n",
    "\n",
    "# 计算滚动最大值\n",
    "rolling_max = cumulative_returns.cummax()\n",
    "\n",
    "# 计算回撤\n",
    "drawdown = cumulative_returns - rolling_max\n",
    "\n",
    "# 计算最大回撤\n",
    "max_drawdown = drawdown.min()\n",
    "\n",
    "# 打印最大回撤\n",
    "print(\"最大回撤: {:.2%}\".format(max_drawdown))\n",
    "\n",
    "def paint():\n",
    "    acc=history.history['acc']\n",
    "    val_acc=history.history['val_acc']\n",
    "    loss=history.history['loss']\n",
    "    val_loss=history.history['val_loss']\n",
    "\n",
    "    epochs=range(len(acc))\n",
    "    plt.plot(epochs,acc,'bo',label='Training acc')\n",
    "    plt.plot(epochs,val_acc,'b',label='Validation acc')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.figure()\n",
    "\n",
    "    plt.plot(epochs,loss,'bo',label='Training loss')\n",
    "    plt.plot(epochs,val_loss,'b',label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()\n",
    "    return plt\n",
    "my_paint=paint()\n",
    "my_paint.show()\n",
    "\n",
    "# 混淆矩阵绘制\n",
    "\n",
    "confusion_matrix = confusion_matrix(target_test, y_pred,labels=[1,0])\n",
    "precision_score=precision_score(target_test, y_pred)\n",
    "recall_score=recall_score(target_test, y_pred)\n",
    "f1_score=f1_score(target_test, y_pred)\n",
    "\n",
    "print('混淆矩阵：',confusion_matrix)\n",
    "print('查准率：',precision_score)\n",
    "print('查全率：',recall_score)\n",
    "print('f1-score:',f1_score)\n",
    "\n",
    "\n",
    "y_predict=model.predict([fif_test,daily_test,wenben_long_term_test,wenben_short_term_test]).reshape(test_num-wenben_back).tolist()\n",
    "fpr,tpr,threshold = roc_curve(target_test, y_predict) ###计算真正率和假正率\n",
    "# print(fpr,tpr,threshold)\n",
    "roc_auc = auc(fpr,tpr)\n",
    "\n",
    "\n",
    "lw = 2\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc) ###假正率为横坐标，真正率为纵坐标做曲线\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# 保存\n",
    "\n",
    "df9=pd.DataFrame({'损失值':loss,'准确率':accuracy,'夏普值':sharp,'收益率':result[2]-1,'最大回撤':[max_drawdown],'查准率':[precision_score],'查全率':[recall_score],'f1-score':[f1_score]})\n",
    "df10=pd.DataFrame({'每日收益率':result[1]})\n",
    "path9='/Users/ccmac/Desktop'\n",
    "df9.to_excel(os.path.join(path9,'数据表.xlsx'),index=False)\n",
    "df10.to_excel(os.path.join(path9,'每日收益率表.xlsx'),index=False)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "t = np.array([1, 2, 3, 4, 5, 6, 7, 8]).reshape([2,4])\n",
    "y = np.cumprod(t, axis=1)\n",
    "print(t)\n",
    "print(y)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf_env]",
   "language": "python",
   "name": "conda-env-tf_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
