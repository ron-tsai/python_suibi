{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49f433dd-af84-4c82-b8e3-1d4950fbdf36",
   "metadata": {},
   "source": [
    "# 1. 导入python库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f02e0e4-772a-47f3-bbd7-68372bf70654",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, recall_score, precision_score, f1_score\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa353efb",
   "metadata": {},
   "source": [
    "# 2. 参数设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccfe2d2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "daily_back=20\n",
    "wenben_back=10\n",
    "\n",
    "wenben_sort=2\n",
    "\n",
    "batch_size=32\n",
    "epochs=100\n",
    "patience=10\n",
    "\n",
    "# LSTM_num=100\n",
    "# dense_num=20\n",
    "\n",
    "\n",
    "mix_file='daily_data.xlsx'\n",
    "first_columns='search_index'\n",
    "\n",
    "\n",
    "total_day=2159 #根据查看数据表，得到数值\n",
    "train_num=1295\n",
    "test_num=total_day-train_num"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1006d29e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "08c9b0fa",
   "metadata": {},
   "source": [
    "# 3. 读取原始数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5a53a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dir='/Users/ccmac/Desktop/完成SCI数据'\n",
    "\n",
    "\n",
    "daily_df=pd.read_excel(os.path.join(new_dir,mix_file))\n",
    "fif_df=pd.read_excel(os.path.join(new_dir,'fif_data.xlsx'))\n",
    "target_df=pd.read_excel(os.path.join(new_dir,'target.xlsx'))\n",
    "wenben_df=pd.read_excel(os.path.join(new_dir,mix_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62075d36-f9cf-4309-a201-1ef014f56cb4",
   "metadata": {},
   "source": [
    "# 4. 标准化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a093f0e5",
   "metadata": {},
   "source": [
    "## 4.1 历史数据标准化函数norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f00c73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(df):\n",
    "    x=df.copy()\n",
    "    open_mean_value = df['open'].mean(axis=0)\n",
    "    high_mean_value = df['high'].mean(axis=0)\n",
    "    low_mean_value = df['low'].mean()\n",
    "    close_mean_value = df['close'].mean()\n",
    "    volumerate_mean_value = df['volume_rate'].mean()\n",
    "\n",
    "    open_std_value = df['open'].std()\n",
    "    high_std_value = df['high'].std()\n",
    "    low_std_value = df['low'].std()\n",
    "    close_std_value = df['close'].std()\n",
    "    volumerate_std_value = df['volume_rate'].std()\n",
    "\n",
    "    x['open']=(df['open']-open_mean_value)/open_std_value\n",
    "    x['high'] = (df['high'] - high_mean_value) / high_std_value\n",
    "    x['low'] =  (df['low'] - low_mean_value) / low_std_value\n",
    "    x['close'] =  (df['close'] - close_mean_value) / close_std_value\n",
    "    x['volume_rate'] = (df['volume_rate'] - volumerate_mean_value) / volumerate_std_value\n",
    "    df=x\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a46668",
   "metadata": {},
   "source": [
    "## 4.2 文本数据标准化函数wenben_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78f471cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wenben_norm(df):\n",
    "    x=df.copy()\n",
    "    sector_score_mean_value = df['sector_score'].mean(axis=0)\n",
    "    search_index_mean_value = df['search_index'].mean(axis=0)\n",
    "\n",
    "    sector_score_std_value = df['sector_score'].std()\n",
    "    search_index_std_value = df['search_index'].std()\n",
    "\n",
    "    x['sector_score']=(df['sector_score']-sector_score_mean_value)/sector_score_std_value\n",
    "    x['search_index'] = (df['search_index'] - search_index_mean_value) / search_index_std_value\n",
    "    \n",
    "    df=x\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a82c845-6afe-43a1-820a-ae8b4e8fb2ab",
   "metadata": {},
   "source": [
    "# 5. 数据切分训练集与测试集"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6911e7",
   "metadata": {},
   "source": [
    "## 5.1 数据切分函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07835973",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(train_num=train_num,wenben_back=wenben_back):\n",
    "    \n",
    "    # 先切分\n",
    "    daily_train_df=daily_df.loc[daily_df.index<train_num]\n",
    "    daily_test_df=daily_df.loc[daily_df.index>=train_num]\n",
    "    \n",
    "    fif_train_df=fif_df.loc[fif_df.index<16*train_num]\n",
    "    fif_test_df=fif_df.loc[fif_df.index>=16*train_num]\n",
    "    \n",
    "    wenben_train_df=wenben_df.loc[wenben_df.index<train_num]\n",
    "    wenben_test_df=wenben_df.loc[wenben_df.index>=train_num]\n",
    "\n",
    "    target_train_df=target_df.loc[target_df.index<train_num]\n",
    "    target_test_df=target_df.loc[target_df.index>=train_num]\n",
    "\n",
    "    \n",
    "    #再进行归一化\n",
    "    daily_train_df=norm(daily_train_df)\n",
    "    daily_test_df=norm(daily_test_df)\n",
    "    fif_train_df=norm(fif_train_df)\n",
    "    fif_test_df=norm(fif_test_df)\n",
    "    wenben_train_df=wenben_norm(wenben_train_df)\n",
    "    wenben_test_df = wenben_norm(wenben_test_df)\n",
    "\n",
    "\n",
    "    return {'daily_train_df':daily_train_df,\n",
    "            'daily_test_df':daily_test_df,\n",
    "            'fif_train_df':fif_train_df,\n",
    "            'fif_test_df':fif_test_df,\n",
    "            'target_train_df':target_train_df,\n",
    "            'target_test_df':target_test_df,\n",
    "            'wenben_train_df':wenben_train_df,\n",
    "            'wenben_test_df': wenben_test_df\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557c115f",
   "metadata": {},
   "source": [
    "## 5.2 进行数据切分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b87cec91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "日频训练切分： (1295, 8)\n",
      "日频测试切分： (864, 8)\n",
      "十五分钟频训练切分： (20720, 6)\n",
      "十五分钟频测试切分： (14000, 6)\n",
      "训练目标切分： (1295, 2)\n",
      "测试目标切分： (875, 2)\n"
     ]
    }
   ],
   "source": [
    "daily_norm_train_df=split_data()['daily_train_df']\n",
    "print('日频训练切分：',daily_norm_train_df.shape)\n",
    "daily_norm_test_df=split_data()['daily_test_df']\n",
    "print('日频测试切分：',daily_norm_test_df.shape)\n",
    "fif_norm_train_df=split_data()['fif_train_df']\n",
    "print('十五分钟频训练切分：',fif_norm_train_df.shape)\n",
    "fif_norm_test_df=split_data()['fif_test_df']\n",
    "print('十五分钟频测试切分：',fif_norm_test_df.shape)\n",
    "target_norm_train_df=split_data()['target_train_df']\n",
    "print('训练目标切分：',target_norm_train_df.shape)\n",
    "target_norm_test_df=split_data()['target_test_df']\n",
    "print('测试目标切分：',target_norm_test_df.shape)\n",
    "wenben_norm_train_df=split_data()['wenben_train_df']\n",
    "wenben_norm_test_df=split_data()['wenben_test_df']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a225c99c-5d81-4930-8aa6-eda77400170e",
   "metadata": {},
   "source": [
    "# 6. 数据转化为神经网络输入格式"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffb3f1f-314a-4710-b96a-62d39be82ec6",
   "metadata": {},
   "source": [
    "## 6.1 建立转化类（返回多个字典）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de355a30-733f-4c79-978d-600334ad64dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data_maker:\n",
    "    def __init__(self,train_num,test_num,fif_back,daily_back,wenben_back):\n",
    "        self.train_num=train_num\n",
    "        self.test_num=test_num\n",
    "        self.fif_back=fif_back\n",
    "        self.daily_back=daily_back\n",
    "        self.wenben_back = wenben_back\n",
    "\n",
    "\n",
    "    def daily_train_data(self,data):\n",
    "        while True:\n",
    "            rows = list(range(self.train_num - self.daily_back)) #总共1650个数据，由于扣除前面20个数据，所以为1630\n",
    "            ### 先构造空（预测日长度*日后移）array\n",
    "            samples = np.zeros((len(rows),\n",
    "                                 self.daily_back,\n",
    "                                 5))\n",
    "            print(samples.shape)\n",
    "            for j in rows:\n",
    "                ### 每一个填入用于预测一天的开盘价到波动率矩阵\n",
    "                samples[j] = data.loc[\n",
    "                                  (data.index >= j) & (data.index < self.daily_back + j),\n",
    "                                  'open':'volume_rate']\n",
    "            print(data.index)\n",
    "            print('日频训练array：',samples.shape)\n",
    "            return samples\n",
    "    def fif_train_data(self,data):\n",
    "        while True:\n",
    "            rows = list(range(self.train_num - self.daily_back))\n",
    "            samples = np.zeros((len(rows),\n",
    "                                 self.fif_back,\n",
    "                                 5))\n",
    "            for j in rows:\n",
    "\n",
    "                samples[j] = data.loc[\n",
    "                              (data.index >= j * self.fif_back ) & (data.index < (j+1) * self.fif_back),\n",
    "                              'open':]\n",
    "            print('十五分钟训练array：',samples.shape)\n",
    "            return samples\n",
    "    def wenben_train_data(self,data):\n",
    "        while True:\n",
    "            rows = list(range(self.train_num - self.daily_back)) #总共1489个数据，由于扣除前面20个数据，所以为1469\n",
    "            samples = np.zeros((len(rows),\n",
    "                                 self.wenben_back,\n",
    "                                 wenben_sort))\n",
    "            for j in rows:\n",
    "\n",
    "                samples[j] = data.loc[\n",
    "                                  (data.index >= j) & (data.index < self.wenben_back + j),\n",
    "                                  first_columns:]\n",
    "            print('文本长期训练array：',samples.shape)\n",
    "            return samples\n",
    "   \n",
    "\n",
    "    def daily_test_data(self,data):\n",
    "        while True:\n",
    "            rows = list(range(self.test_num - self.daily_back))\n",
    "            print(self.test_num,self.daily_back)\n",
    "            print(rows)\n",
    "            samples = np.zeros((len(rows),\n",
    "                                self.daily_back,\n",
    "                                 5))\n",
    "            for j in rows:\n",
    "\n",
    "\n",
    "                samples[j] = data.loc[\n",
    "                                  (data.index >= self.train_num+j) & (data.index < self.train_num+self.daily_back + j),\n",
    "                                  'open':'volume_rate']\n",
    "            print('日测试array：',samples.shape)\n",
    "            print('试一试index', data.index,'train_num',self.train_num)\n",
    "            return samples\n",
    "\n",
    "    def wenben_test_data(self, data):\n",
    "        while True:\n",
    "            rows = list(range(self.test_num - self.daily_back))\n",
    "            samples = np.zeros((len(rows),\n",
    "                                self.wenben_back,\n",
    "                                wenben_sort))\n",
    "            for j in rows:\n",
    "                samples[j] = data.loc[\n",
    "                             (data.index >= self.train_num + j) & (data.index < self.train_num + self.wenben_back + j),\n",
    "                             first_columns:]\n",
    "            print('长期文本测试array：', samples.shape)\n",
    "            return samples\n",
    "   \n",
    "    def fif_test_data(self,data):\n",
    "        while True:\n",
    "            rows = list(range(self.test_num - self.daily_back))\n",
    "            samples = np.zeros((len(rows),\n",
    "                                self.fif_back,\n",
    "                                 5))\n",
    "            for j in rows:\n",
    "\n",
    "\n",
    "                samples[j] = data.loc[\n",
    "                                 (data.index >= 16*self.train_num+(j) * self.fif_back) & (data.index < 16*self.train_num+(j+1) * self.fif_back),\n",
    "                                 'open':]\n",
    "            print('十五分钟测试array：',samples.shape)\n",
    "            return samples\n",
    "    def target_train_data(self,data):\n",
    "        while True:\n",
    "            rows = list(range(self.train_num-self.daily_back))\n",
    "            targets = np.zeros((len(rows),))\n",
    "            for j in rows:\n",
    "\n",
    "\n",
    "                targets[j] = data.loc[data.index == j, 'target'].iloc[0] #根据提示，添加了.iloc[0]\n",
    "            print('训练标签array',targets.shape)\n",
    "            return targets\n",
    "    def target_test_data(self,data):\n",
    "        while True:\n",
    "            rows = list(range(self.test_num-self.daily_back))\n",
    "            targets = np.zeros((len(rows),))\n",
    "            for j in rows:\n",
    "\n",
    "\n",
    "                targets[j] = data.loc[data.index == self.train_num+j, 'target'].iloc[0] ##出问题：应该是。而不是***：data.index == self.train_num+j\n",
    "            print(targets.shape)\n",
    "            return targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d109eb0-7de5-414a-a276-f81fcefe1269",
   "metadata": {},
   "source": [
    "## 6.2 设置类方法里的参数，赋值给origin_data_maker，仍然是一个class类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e39a13e8-0b0d-4cb8-b630-a142d4529615",
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_data_maker=Data_maker(train_num=train_num,test_num=test_num,fif_back=16,daily_back=daily_back,wenben_back=wenben_back)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84200b8",
   "metadata": {},
   "source": [
    "# 6.3 调用类中的方法,处理原始数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a26f72f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1275, 20, 5)\n",
      "Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,\n",
      "       ...\n",
      "       1285, 1286, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1294],\n",
      "      dtype='int64', length=1295)\n",
      "日频训练array： (1275, 20, 5)\n",
      "864 20\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843]\n",
      "日测试array： (844, 20, 5)\n",
      "试一试index Index([1295, 1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1304,\n",
      "       ...\n",
      "       2149, 2150, 2151, 2152, 2153, 2154, 2155, 2156, 2157, 2158],\n",
      "      dtype='int64', length=864) train_num 1295\n",
      "十五分钟训练array： (1275, 16, 5)\n",
      "十五分钟测试array： (844, 16, 5)\n",
      "文本长期训练array： (1275, 10, 2)\n",
      "长期文本测试array： (844, 10, 2)\n",
      "训练标签array (1275,)\n",
      "(844,)\n"
     ]
    }
   ],
   "source": [
    "DM = origin_data_maker\n",
    "\n",
    "daily_train_prepared = DM.daily_train_data(daily_norm_train_df)\n",
    "daily_test_prepared = DM.daily_test_data(daily_norm_test_df)\n",
    "\n",
    "fif_train_prepared = DM.fif_train_data(fif_norm_train_df)\n",
    "fif_test_prepared = DM.fif_test_data(fif_norm_test_df)\n",
    "\n",
    "wenben_train_prepared = DM.wenben_train_data(wenben_norm_train_df)\n",
    "wenben_test_prepared = DM.wenben_test_data(wenben_norm_test_df)\n",
    "\n",
    "target_train_prepared = DM.target_train_data(target_norm_train_df)\n",
    "target_test_prepared = DM.target_test_data(target_norm_test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "082f7ca9-9c73-4357-95e4-b0639fc865cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# daily_train_prepared\n",
    "# daily_test_prepared\n",
    "\n",
    "# fif_train_prepared\n",
    "# fif_test_prepared \n",
    "\n",
    "# wenben_train_prepared\n",
    "# wenben_test_prepared\n",
    "\n",
    "# target_train_prepared\n",
    "# target_test_prepared"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb802e8a",
   "metadata": {},
   "source": [
    "# 7. 神经网络模型训练"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9ca801-990d-4205-a794-e3784edf76a1",
   "metadata": {},
   "source": [
    "## 7.1 模型建立 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f40a1c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def my_model(daily_back, LSTM_num, dense_num, learning_rate):\n",
    "    # 15分钟频输入\n",
    "    fif_min_input = Input(shape=(16, 5), dtype='float32', name='fif_min_input')\n",
    "    Conv1D_fif = layers.Conv1D(16, 1, strides=1)(fif_min_input)\n",
    "    LSTM_fif = layers.LSTM(LSTM_num)(Conv1D_fif)\n",
    "    \n",
    "    # 日频输入\n",
    "    daily_input = Input(shape=(daily_back, 5), dtype='float32', name='daily_input')\n",
    "    Conv1D_daily = layers.Conv1D(16, 1, strides=1)(daily_input)\n",
    "    LSTM_daily = layers.LSTM(LSTM_num)(Conv1D_daily)\n",
    "    \n",
    "    # 合并与全连接\n",
    "    concatenated = layers.concatenate([LSTM_fif, LSTM_daily], axis=-1)\n",
    "    alloy = layers.Dense(dense_num, activation='relu')(concatenated)\n",
    "    dropout = layers.Dropout(0.2)(alloy)\n",
    "    output = layers.Dense(1, activation='sigmoid')(dropout)\n",
    "    \n",
    "    model = Model([fif_min_input, daily_input], output)\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), \n",
    "                  loss='binary_crossentropy', \n",
    "                  metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d59d6ec-c99d-4d64-af71-5b7e777e4eae",
   "metadata": {},
   "source": [
    "# 创建早停机制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c87ecab-1d59-4ef6-a658-dc4c9ccae6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建早停回调\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',    # 监控验证集损失\n",
    "    patience=patience,           # 如果连续10个epoch验证集损失没有改善，则停止训练\n",
    "    restore_best_weights=True  # 恢复验证集损失最低时的模型权重\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cb0845-d365-4979-84d5-90540b299960",
   "metadata": {},
   "source": [
    "# 2. 定义适应度函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8dbc63ea-2505-488f-adc7-0a778f7879a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def fitness_function(params):\n",
    "    LSTM_num = int(params[0])\n",
    "    dense_num = int(params[1])\n",
    "    learning_rate = params[2]\n",
    "\n",
    "\n",
    "    \n",
    "    model = my_model(daily_back=daily_back,  # 替换为实际daily_back值\n",
    "                     LSTM_num=LSTM_num,\n",
    "                     dense_num=dense_num,\n",
    "                     learning_rate=learning_rate)\n",
    "    \n",
    "    history = model.fit(x=[fif_train_prepared,daily_train_prepared],y=target_train_prepared,batch_size=batch_size,\n",
    "                validation_split=0.25,epochs=epochs,callbacks=[early_stopping])\n",
    "    return history.history['val_loss'][-1]  # 返回验证损失（越小越好）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcb4aca-acf5-42c1-a3e3-a0146a1b4310",
   "metadata": {},
   "source": [
    "# 3. 实现麻雀搜索算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ffb38a63-5310-43c4-b7b7-6181f62e545f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparrow(pop_size, max_iter, dim, lower_bounds, upper_bounds, fitness_func):\n",
    "    pop = np.random.uniform(low=lower_bounds, high=upper_bounds, size=(pop_size, dim))\n",
    "    fitness = np.array([fitness_func(ind) for ind in pop])\n",
    "    best_idx = np.argmin(fitness)\n",
    "    best_sol = pop[best_idx].copy()\n",
    "    best_fit = fitness[best_idx]\n",
    "\n",
    "    for t in range(max_iter):\n",
    "        # 排序\n",
    "        sorted_idx = np.argsort(fitness)\n",
    "        pop = pop[sorted_idx]\n",
    "        fitness = fitness[sorted_idx]\n",
    "\n",
    "        # 发现者策略\n",
    "        for i in range(int(pop_size * 0.2)):\n",
    "            if np.random.rand() < 0.8:\n",
    "                pop[i] *= np.exp(-i / (np.random.rand() * max_iter))\n",
    "            else:\n",
    "                pop[i] += np.random.normal(0, 1)\n",
    "            \n",
    "            # 每次更新后立即检查边界\n",
    "            pop[i] = np.clip(pop[i], lower_bounds, upper_bounds)\n",
    "\n",
    "        # 跟随者策略 - 改进矩阵计算\n",
    "        for i in range(int(pop_size * 0.2), pop_size):\n",
    "            if i > pop_size / 2:\n",
    "                pop[i] = np.random.normal(0, 1) * np.exp((pop[-1] - pop[i]) / (i ** 2))\n",
    "            else:\n",
    "                # 简化矩阵计算，避免奇异矩阵问题\n",
    "                A = np.random.choice([-1, 1], size=dim)\n",
    "                pop[i] = pop[0] + A * (pop[0] - pop[i])\n",
    "            \n",
    "            # 每次更新后立即检查边界\n",
    "            pop[i] = np.clip(pop[i], lower_bounds, upper_bounds)\n",
    "\n",
    "        # 警戒者策略\n",
    "        for i in range(pop_size):\n",
    "            if fitness[i] > best_fit:\n",
    "                pop[i] = best_sol + np.random.normal(0, 1)\n",
    "                # 立即检查边界\n",
    "                pop[i] = np.clip(pop[i], lower_bounds, upper_bounds)\n",
    "\n",
    "        # 更新最佳解\n",
    "        fitness = np.array([fitness_func(ind) for ind in pop])\n",
    "        current_best_idx = np.argmin(fitness)\n",
    "        if fitness[current_best_idx] < best_fit:\n",
    "            best_fit = fitness[current_best_idx]\n",
    "            best_sol = pop[current_best_idx].copy()\n",
    "\n",
    "    return best_sol, best_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a102678-07e2-469d-9ec9-d9e8ca85b71a",
   "metadata": {},
   "source": [
    "# 4. 运行优化并训练最终模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdda013f-3939-4290-af12-48381f4273d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - acc: 0.4866 - loss: 0.7247 - val_acc: 0.5423 - val_loss: 0.7100\n",
      "Epoch 2/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.5124 - loss: 0.6866 - val_acc: 0.5423 - val_loss: 0.6978\n",
      "Epoch 3/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.5270 - loss: 0.6869 - val_acc: 0.5423 - val_loss: 0.6905\n",
      "Epoch 4/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - acc: 0.5586 - loss: 0.6862 - val_acc: 0.5580 - val_loss: 0.6883\n",
      "Epoch 5/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - acc: 0.5416 - loss: 0.6864 - val_acc: 0.5361 - val_loss: 0.6994\n",
      "Epoch 6/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 0.5509 - loss: 0.6854 - val_acc: 0.5455 - val_loss: 0.6965\n",
      "Epoch 7/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - acc: 0.5291 - loss: 0.6862 - val_acc: 0.5329 - val_loss: 0.7086\n",
      "Epoch 8/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 0.5565 - loss: 0.6833 - val_acc: 0.5423 - val_loss: 0.7020\n",
      "Epoch 9/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 0.5334 - loss: 0.6857 - val_acc: 0.5549 - val_loss: 0.6895\n",
      "Epoch 10/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - acc: 0.5543 - loss: 0.6754 - val_acc: 0.5298 - val_loss: 0.7172\n",
      "Epoch 11/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 0.5833 - loss: 0.6717 - val_acc: 0.5517 - val_loss: 0.7009\n",
      "Epoch 12/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - acc: 0.5796 - loss: 0.6670 - val_acc: 0.5392 - val_loss: 0.6940\n",
      "Epoch 13/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - acc: 0.5586 - loss: 0.6817 - val_acc: 0.5611 - val_loss: 0.7243\n",
      "Epoch 14/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - acc: 0.5932 - loss: 0.6651 - val_acc: 0.5329 - val_loss: 0.6977\n",
      "Epoch 1/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - acc: 0.5084 - loss: 0.7260 - val_acc: 0.5298 - val_loss: 0.7299\n",
      "Epoch 2/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - acc: 0.5348 - loss: 0.6954 - val_acc: 0.5392 - val_loss: 0.6960\n",
      "Epoch 3/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - acc: 0.5411 - loss: 0.7015 - val_acc: 0.5047 - val_loss: 0.6959\n",
      "Epoch 4/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - acc: 0.4879 - loss: 0.7014 - val_acc: 0.5423 - val_loss: 0.6967\n",
      "Epoch 5/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.5363 - loss: 0.6856 - val_acc: 0.5392 - val_loss: 0.6950\n",
      "Epoch 6/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - acc: 0.5419 - loss: 0.6857 - val_acc: 0.5392 - val_loss: 0.6938\n",
      "Epoch 7/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - acc: 0.5299 - loss: 0.6867 - val_acc: 0.5172 - val_loss: 0.6918\n",
      "Epoch 8/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - acc: 0.5404 - loss: 0.6876 - val_acc: 0.5204 - val_loss: 0.6974\n",
      "Epoch 9/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - acc: 0.5554 - loss: 0.6788 - val_acc: 0.4608 - val_loss: 0.6945\n",
      "Epoch 10/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - acc: 0.4819 - loss: 0.6922 - val_acc: 0.5423 - val_loss: 0.6985\n",
      "Epoch 11/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - acc: 0.5203 - loss: 0.6931 - val_acc: 0.5423 - val_loss: 0.6888\n",
      "Epoch 12/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - acc: 0.5206 - loss: 0.6921 - val_acc: 0.5423 - val_loss: 0.6934\n",
      "Epoch 13/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - acc: 0.5354 - loss: 0.6907 - val_acc: 0.5423 - val_loss: 0.6932\n",
      "Epoch 14/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - acc: 0.5339 - loss: 0.6856 - val_acc: 0.5423 - val_loss: 0.6949\n",
      "Epoch 15/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - acc: 0.5233 - loss: 0.6873 - val_acc: 0.5423 - val_loss: 0.7030\n",
      "Epoch 16/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - acc: 0.5624 - loss: 0.6849 - val_acc: 0.5423 - val_loss: 0.6883\n",
      "Epoch 17/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - acc: 0.5448 - loss: 0.6901 - val_acc: 0.5423 - val_loss: 0.6887\n",
      "Epoch 18/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - acc: 0.5028 - loss: 0.6924 - val_acc: 0.5423 - val_loss: 0.6861\n",
      "Epoch 19/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - acc: 0.5409 - loss: 0.6874 - val_acc: 0.5423 - val_loss: 0.6878\n",
      "Epoch 20/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - acc: 0.5086 - loss: 0.6912 - val_acc: 0.5423 - val_loss: 0.6890\n",
      "Epoch 21/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - acc: 0.5366 - loss: 0.6891 - val_acc: 0.5423 - val_loss: 0.6881\n",
      "Epoch 22/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - acc: 0.5044 - loss: 0.6917 - val_acc: 0.5423 - val_loss: 0.6971\n",
      "Epoch 23/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - acc: 0.5324 - loss: 0.6909 - val_acc: 0.5423 - val_loss: 0.6894\n",
      "Epoch 24/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - acc: 0.5404 - loss: 0.6881 - val_acc: 0.5423 - val_loss: 0.6928\n",
      "Epoch 25/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - acc: 0.5371 - loss: 0.6852 - val_acc: 0.5423 - val_loss: 0.6983\n",
      "Epoch 26/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - acc: 0.5382 - loss: 0.6939 - val_acc: 0.5423 - val_loss: 0.6892\n",
      "Epoch 27/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - acc: 0.5465 - loss: 0.6888 - val_acc: 0.5423 - val_loss: 0.6911\n",
      "Epoch 28/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - acc: 0.5215 - loss: 0.6882 - val_acc: 0.5423 - val_loss: 0.6958\n",
      "Epoch 1/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - acc: 0.4917 - loss: 0.7223 - val_acc: 0.5423 - val_loss: 0.7517\n",
      "Epoch 2/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 0.5695 - loss: 0.6702 - val_acc: 0.5549 - val_loss: 0.6893\n",
      "Epoch 3/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 0.5245 - loss: 0.6922 - val_acc: 0.5392 - val_loss: 0.7231\n",
      "Epoch 4/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - acc: 0.4869 - loss: 0.6985 - val_acc: 0.5549 - val_loss: 0.7762\n",
      "Epoch 5/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - acc: 0.5686 - loss: 0.6921 - val_acc: 0.5455 - val_loss: 0.6951\n",
      "Epoch 6/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - acc: 0.5344 - loss: 0.6874 - val_acc: 0.5517 - val_loss: 0.6985\n",
      "Epoch 7/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - acc: 0.5610 - loss: 0.6782 - val_acc: 0.5455 - val_loss: 0.6921\n",
      "Epoch 8/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - acc: 0.5139 - loss: 0.6854 - val_acc: 0.5611 - val_loss: 0.7006\n",
      "Epoch 9/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - acc: 0.5800 - loss: 0.6759 - val_acc: 0.5486 - val_loss: 0.7432\n",
      "Epoch 10/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - acc: 0.5870 - loss: 0.6691 - val_acc: 0.5768 - val_loss: 0.6945\n",
      "Epoch 11/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - acc: 0.5766 - loss: 0.6743 - val_acc: 0.5392 - val_loss: 0.7371\n",
      "Epoch 12/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - acc: 0.5682 - loss: 0.6796 - val_acc: 0.5674 - val_loss: 0.7183\n",
      "Epoch 1/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - acc: 0.5012 - loss: 0.7586 - val_acc: 0.5580 - val_loss: 0.6858\n",
      "Epoch 2/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - acc: 0.5392 - loss: 0.6888 - val_acc: 0.5423 - val_loss: 0.6885\n",
      "Epoch 3/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - acc: 0.5289 - loss: 0.6911 - val_acc: 0.5423 - val_loss: 0.6886\n",
      "Epoch 4/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - acc: 0.5423 - loss: 0.6856 - val_acc: 0.5423 - val_loss: 0.6893\n",
      "Epoch 5/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - acc: 0.5351 - loss: 0.6868 - val_acc: 0.5423 - val_loss: 0.6909\n",
      "Epoch 6/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - acc: 0.5207 - loss: 0.6841 - val_acc: 0.5423 - val_loss: 0.6921\n",
      "Epoch 7/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - acc: 0.5374 - loss: 0.6969 - val_acc: 0.5423 - val_loss: 0.6901\n",
      "Epoch 8/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - acc: 0.5394 - loss: 0.6909 - val_acc: 0.5423 - val_loss: 0.6899\n",
      "Epoch 9/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - acc: 0.5194 - loss: 0.6927 - val_acc: 0.5423 - val_loss: 0.6900\n",
      "Epoch 10/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - acc: 0.5080 - loss: 0.6939 - val_acc: 0.5423 - val_loss: 0.6898\n",
      "Epoch 11/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - acc: 0.5246 - loss: 0.6922 - val_acc: 0.5423 - val_loss: 0.6899\n",
      "Epoch 1/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - acc: 0.5262 - loss: 0.7488 - val_acc: 0.4577 - val_loss: 0.7066\n",
      "Epoch 2/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - acc: 0.5164 - loss: 0.7026 - val_acc: 0.5423 - val_loss: 0.6901\n",
      "Epoch 3/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - acc: 0.5173 - loss: 0.6929 - val_acc: 0.5423 - val_loss: 0.6897\n",
      "Epoch 4/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - acc: 0.5280 - loss: 0.6916 - val_acc: 0.5423 - val_loss: 0.6898\n",
      "Epoch 5/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - acc: 0.5265 - loss: 0.6919 - val_acc: 0.5423 - val_loss: 0.6899\n",
      "Epoch 6/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - acc: 0.5425 - loss: 0.6900 - val_acc: 0.5423 - val_loss: 0.6898\n",
      "Epoch 7/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - acc: 0.5348 - loss: 0.6907 - val_acc: 0.5423 - val_loss: 0.6901\n",
      "Epoch 8/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.5300 - loss: 0.6914 - val_acc: 0.5423 - val_loss: 0.6898\n",
      "Epoch 9/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - acc: 0.5320 - loss: 0.6912 - val_acc: 0.5423 - val_loss: 0.6899\n",
      "Epoch 10/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - acc: 0.5294 - loss: 0.6914 - val_acc: 0.5423 - val_loss: 0.6899\n",
      "Epoch 11/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.5008 - loss: 0.6948 - val_acc: 0.5423 - val_loss: 0.6901\n",
      "Epoch 12/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - acc: 0.5292 - loss: 0.6916 - val_acc: 0.5423 - val_loss: 0.6898\n",
      "Epoch 13/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.5324 - loss: 0.6911 - val_acc: 0.5423 - val_loss: 0.6897\n",
      "Epoch 14/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - acc: 0.5131 - loss: 0.6937 - val_acc: 0.5423 - val_loss: 0.6899\n",
      "Epoch 15/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.5480 - loss: 0.6893 - val_acc: 0.5423 - val_loss: 0.6898\n",
      "Epoch 16/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - acc: 0.5496 - loss: 0.6889 - val_acc: 0.5423 - val_loss: 0.6898\n",
      "Epoch 17/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - acc: 0.5122 - loss: 0.6936 - val_acc: 0.5423 - val_loss: 0.6902\n",
      "Epoch 18/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - acc: 0.5238 - loss: 0.6921 - val_acc: 0.5423 - val_loss: 0.6899\n",
      "Epoch 19/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - acc: 0.5246 - loss: 0.6922 - val_acc: 0.5423 - val_loss: 0.6899\n",
      "Epoch 20/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.5194 - loss: 0.6927 - val_acc: 0.5423 - val_loss: 0.6900\n",
      "Epoch 21/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - acc: 0.5117 - loss: 0.6935 - val_acc: 0.5423 - val_loss: 0.6897\n",
      "Epoch 22/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.5526 - loss: 0.6885 - val_acc: 0.5423 - val_loss: 0.6898\n",
      "Epoch 23/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - acc: 0.5406 - loss: 0.6901 - val_acc: 0.5423 - val_loss: 0.6901\n",
      "Epoch 24/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.5391 - loss: 0.6905 - val_acc: 0.5423 - val_loss: 0.6899\n",
      "Epoch 25/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - acc: 0.5457 - loss: 0.6896 - val_acc: 0.5423 - val_loss: 0.6900\n",
      "Epoch 26/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - acc: 0.5195 - loss: 0.6926 - val_acc: 0.5423 - val_loss: 0.6900\n",
      "Epoch 27/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - acc: 0.5302 - loss: 0.6915 - val_acc: 0.5423 - val_loss: 0.6899\n",
      "Epoch 28/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - acc: 0.5134 - loss: 0.6933 - val_acc: 0.5423 - val_loss: 0.6902\n",
      "Epoch 29/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - acc: 0.5478 - loss: 0.6897 - val_acc: 0.5423 - val_loss: 0.6898\n",
      "Epoch 30/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - acc: 0.5386 - loss: 0.6903 - val_acc: 0.5423 - val_loss: 0.6898\n",
      "Epoch 31/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - acc: 0.5275 - loss: 0.6917 - val_acc: 0.5423 - val_loss: 0.6900\n",
      "Epoch 1/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - acc: 0.5220 - loss: 0.7047 - val_acc: 0.5392 - val_loss: 0.6989\n",
      "Epoch 2/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - acc: 0.5312 - loss: 0.6930 - val_acc: 0.5517 - val_loss: 0.6885\n",
      "Epoch 3/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - acc: 0.5423 - loss: 0.6860 - val_acc: 0.5455 - val_loss: 0.7082\n",
      "Epoch 4/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.5503 - loss: 0.6815 - val_acc: 0.5517 - val_loss: 0.6929\n",
      "Epoch 5/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - acc: 0.5607 - loss: 0.6759 - val_acc: 0.5455 - val_loss: 0.6938\n",
      "Epoch 6/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - acc: 0.5628 - loss: 0.6853 - val_acc: 0.5580 - val_loss: 0.6919\n",
      "Epoch 7/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - acc: 0.5790 - loss: 0.6785 - val_acc: 0.5517 - val_loss: 0.7041\n",
      "Epoch 8/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - acc: 0.5897 - loss: 0.6747 - val_acc: 0.5392 - val_loss: 0.6878\n",
      "Epoch 9/100\n",
      "\u001b[1m28/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - acc: 0.5375 - loss: 0.6802"
     ]
    }
   ],
   "source": [
    "# 超参数范围（LSTM_num, dense_num, learning_rate）\n",
    "lower_bounds = [64, 16, 1e-4]\n",
    "upper_bounds = [256, 64, 1e-2]\n",
    "pop_size = 10\n",
    "max_iter = 5\n",
    "\n",
    "best_params, best_fitness =sparrow(pop_size, max_iter, 3, lower_bounds, upper_bounds, fitness_function)\n",
    "\n",
    "print(f\"最佳参数：LSTM_num={int(best_params[0])}, dense_num={int(best_params[1])}, learning_rate={best_params[2]}\")\n",
    "print(f\"最佳验证准确率：{best_fitness}\")\n",
    "\n",
    "\n",
    "# 用最佳参数训练最终模型\n",
    "final_model = my_model(daily_back=daily_back,  # 替换为实际值\n",
    "                       LSTM_num=int(best_params[0]),\n",
    "                       dense_num=int(best_params[1]),\n",
    "                       learning_rate=best_params[2])\n",
    "final_model.fit(x=[fif_train_prepared,daily_train_prepared],y=target_train_prepared,batch_size=batch_size,\n",
    "                validation_split=0.25,epochs=epochs,callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a065f8c",
   "metadata": {},
   "source": [
    "## 7.2 模型滞后时长赋值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993a90eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model=my_model(daily_back=daily_back)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e025ba5e-a33c-4474-9138-18ad1474565b",
   "metadata": {},
   "source": [
    "## 7.3 添加输出模型参数的代码块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42bfef1-b9f0-4103-9a4d-c90f8bb13126",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(final_model, to_file='model_structure.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8620eccf",
   "metadata": {},
   "source": [
    "## 7.4 model.fit(输入训练数据x，标志y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebf83ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "history = final_model.fit(x=[fif_train_prepared,daily_train_prepared],y=target_train_prepared,\n",
    "                          batch_size=batch_size,validation_split=0.25,epochs=epochs,callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd0ae96",
   "metadata": {},
   "source": [
    "## 7.5 model.evaluate(输入测试数据)，进行模型预测性能测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bd90e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss,accuracy = final_model.evaluate([fif_test_prepared,daily_test_prepared],y=target_test_prepared)\n",
    "print(loss,accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62e60b0-7dc9-47e4-b131-df7a159dbf01",
   "metadata": {},
   "source": [
    "# 8. 回测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9607cca",
   "metadata": {},
   "source": [
    "# 构建y的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc23d49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_y_pred():\n",
    "    y_predict=final_model.predict([fif_test_prepared,daily_test_prepared],batch_size=1).reshape(test_num-daily_back).tolist() ###batch_size要设为1，不然evaluate和predict结果不同\n",
    "    y_pred=[]\n",
    "    for i,v in enumerate(y_predict):\n",
    "        if v>0.5:\n",
    "            y_pred.append(1)\n",
    "        if v<0.5:\n",
    "            y_pred.append(0)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915e4535",
   "metadata": {},
   "source": [
    "# 制作y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191b4fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=gen_y_pred()\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0f800a",
   "metadata": {},
   "source": [
    "#  构建使用测试集作为回测数据的类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c753f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Back_tes_trader:\n",
    "    def __init__(self,train_num,daily_back):\n",
    "        self.train_num=train_num\n",
    "        self.daily_back=daily_back\n",
    "    def daily_test_data(self,data):\n",
    "        while True:\n",
    "            samples = data.loc[\n",
    "                data.index >=self.train_num+self.daily_back ,\n",
    "                ['open','close']]\n",
    "            print(data.index)\n",
    "            return samples\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8bb8f4",
   "metadata": {},
   "source": [
    "# 回测数据集代入参数，形成回撤数据back_tes_trader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9555c139",
   "metadata": {},
   "outputs": [],
   "source": [
    "back_tes_trader=Back_tes_trader(train_num=train_num,daily_back=daily_back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b72e4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_back_trader(train_num=train_num):\n",
    "\n",
    "    daily_test_df=daily_df.loc[daily_df.index>=train_num]\n",
    "\n",
    "    return {'daily_test_df':daily_test_df}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0caaf456",
   "metadata": {},
   "outputs": [],
   "source": [
    "back_df=split_back_trader()['daily_test_df']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff686572",
   "metadata": {},
   "outputs": [],
   "source": [
    "back_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd75b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "backtrader_df=back_tes_trader.daily_test_data(back_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8c3651",
   "metadata": {},
   "source": [
    "# 形成day_rate_of_return日内收益率，和rate_of_return隔夜收益率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84028e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "backtrader_df['rate_of_return'] = backtrader_df['close'].rolling(2).apply(lambda x: x[1] / x[0] - 1, raw=True)\n",
    "backtrader_df['day_rate_of_return']=backtrader_df['close']/backtrader_df['open']-1\n",
    "\n",
    "clo_1=backtrader_df.loc[(backtrader_df.index<total_day-1),\"close\"].tolist()\n",
    "\n",
    "print(len(clo_1))\n",
    "print(backtrader_df.loc[(backtrader_df.index>=train_num+daily_back+1),:])\n",
    "backtrader_df.loc[(backtrader_df.index>=train_num+daily_back+1),'last_close']=clo_1\n",
    "backtrader_df['sale_rate_of_return']=backtrader_df['open']/backtrader_df['last_close']-1\n",
    "\n",
    "\n",
    "print(backtrader_df)\n",
    "print(backtrader_df.shape)\n",
    "trade_day_return_list=[]\n",
    "return_list=[]\n",
    "every_day_return_list=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94506474",
   "metadata": {},
   "source": [
    "# 回测交易逻辑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2a5071",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtrader(list,df):\n",
    "    a=0\n",
    "\n",
    "    rate_of_return = 1\n",
    "    for i,v in enumerate(list):\n",
    "        if (v ==1)&(a==0):\n",
    "            b=(1 + df.loc[train_num+daily_back + i, 'day_rate_of_return'])\n",
    "            rate_of_return= rate_of_return * b\n",
    "            a=1\n",
    "            trade_day_return_list.append(b-1)\n",
    "            return_list.append(rate_of_return)\n",
    "            every_day_return_list.append(b - 1)\n",
    "\n",
    "        elif (v ==1)&(a==1):\n",
    "            b=(1 + df.loc[train_num+daily_back + i, 'rate_of_return'])\n",
    "            rate_of_return= rate_of_return *b\n",
    "            a=a\n",
    "            trade_day_return_list.append(b-1)\n",
    "            return_list.append(rate_of_return)\n",
    "            every_day_return_list.append(b - 1)\n",
    "        elif (v==0)&(a==0):\n",
    "            rate_of_return=rate_of_return\n",
    "            a=a\n",
    "            every_day_return_list.append(0)\n",
    "\n",
    "        elif (v==0)&(a==1):\n",
    "            a=0\n",
    "            b = (1 + df.loc[train_num+daily_back + i, 'sale_rate_of_return'])\n",
    "            rate_of_return=rate_of_return*b\n",
    "            trade_day_return_list.append(b-1)\n",
    "            every_day_return_list.append(b - 1)\n",
    "            return_list.append(rate_of_return)\n",
    "    return a,trade_day_return_list,rate_of_return,return_list,every_day_return_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a6e92b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eda96a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "result=backtrader(y_pred,backtrader_df)\n",
    "# print(result[1])\n",
    "# print(result[2])\n",
    "# print(result[3])\n",
    "pingjun_nian_jiaoyi_ri=240*len(result[1])/(len(y_pred))\n",
    "sharp=(np.mean(result[1]))/(np.std(result[1],ddof=1))*np.sqrt(pingjun_nian_jiaoyi_ri)\n",
    "# sharp1=(np.mean(result[4]))/(np.std(result[4]))\n",
    "# print('夏普比率--：',sharp1)\n",
    "print('夏普比率：',sharp)\n",
    "print('收益率：',result[2]-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2ded5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e894d8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "returns=result[3]\n",
    "returns = [ret - 1 for ret in returns]\n",
    "# returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c359f589",
   "metadata": {},
   "outputs": [],
   "source": [
    "returns=result[3]\n",
    "returns = [ret - 1 for ret in returns]\n",
    "\n",
    "# 将收益率列表转换为pandas的Series对象，方便处理\n",
    "returns_series = pd.Series(returns)\n",
    "\n",
    "# 计算累计收益率\n",
    "cumulative_returns = (1 + returns_series).cumprod() - 1\n",
    "\n",
    "# 计算滚动最大值\n",
    "rolling_max = cumulative_returns.cummax()\n",
    "\n",
    "# 计算回撤\n",
    "drawdown = cumulative_returns - rolling_max\n",
    "\n",
    "# 计算最大回撤\n",
    "max_drawdown = drawdown.min()\n",
    "\n",
    "# 打印最大回撤\n",
    "print(\"最大回撤: {:.2%}\".format(max_drawdown))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d346e244",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb03bdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def paint():\n",
    "    acc=history.history['acc']\n",
    "    val_acc=history.history['val_acc']\n",
    "    loss=history.history['loss']\n",
    "    val_loss=history.history['val_loss']\n",
    "\n",
    "    epochs=range(len(acc))\n",
    "    plt.plot(epochs,acc,'bo',label='Training acc')\n",
    "    plt.plot(epochs,val_acc,'b',label='Validation acc')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.figure()\n",
    "\n",
    "    plt.plot(epochs,loss,'bo',label='Training loss')\n",
    "    plt.plot(epochs,val_loss,'b',label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()\n",
    "    return plt\n",
    "my_paint=paint()\n",
    "my_paint.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff449cf1",
   "metadata": {},
   "source": [
    "# 混淆矩阵绘制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2eaf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = confusion_matrix(target_test_prepared, y_pred,labels=[1,0])\n",
    "precision_score=precision_score(target_test_prepared, y_pred)\n",
    "recall_score=recall_score(target_test_prepared, y_pred)\n",
    "f1_score=f1_score(target_test_prepared, y_pred)\n",
    "\n",
    "print('混淆矩阵：',confusion_matrix)\n",
    "print('查准率：',precision_score)\n",
    "print('查全率：',recall_score)\n",
    "print('f1-score:',f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52941452",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict=final_model.predict([fif_test_prepared,daily_test_prepared]).reshape(test_num-daily_back).tolist()\n",
    "fpr,tpr,threshold = roc_curve(target_test_prepared, y_predict) ###计算真正率和假正率\n",
    "# print(fpr,tpr,threshold)\n",
    "roc_auc = auc(fpr,tpr)\n",
    "\n",
    "\n",
    "lw = 2\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc) ###假正率为横坐标，真正率为纵坐标做曲线\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302466a8",
   "metadata": {},
   "source": [
    "# 保存"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "tf_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
