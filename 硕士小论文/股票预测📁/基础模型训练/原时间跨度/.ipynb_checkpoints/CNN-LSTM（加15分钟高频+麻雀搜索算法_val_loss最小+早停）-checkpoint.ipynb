{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49f433dd-af84-4c82-b8e3-1d4950fbdf36",
   "metadata": {},
   "source": [
    "# 1. 导入python库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f02e0e4-772a-47f3-bbd7-68372bf70654",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, recall_score, precision_score, f1_score\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa353efb",
   "metadata": {},
   "source": [
    "# 2. 参数设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccfe2d2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "daily_back=20\n",
    "wenben_back=10\n",
    "\n",
    "wenben_sort=2\n",
    "\n",
    "batch_size=32\n",
    "epochs=100\n",
    "patience=10\n",
    "\n",
    "# LSTM_num=100\n",
    "# dense_num=20\n",
    "\n",
    "\n",
    "mix_file='daily_data.xlsx'\n",
    "first_columns='search_index'\n",
    "\n",
    "\n",
    "total_day=2159 #根据查看数据表，得到数值\n",
    "train_num=1295\n",
    "test_num=total_day-train_num"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1006d29e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "08c9b0fa",
   "metadata": {},
   "source": [
    "# 3. 读取原始数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5a53a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dir='/Users/ccmac/Desktop/完成SCI数据'\n",
    "\n",
    "\n",
    "daily_df=pd.read_excel(os.path.join(new_dir,mix_file))\n",
    "fif_df=pd.read_excel(os.path.join(new_dir,'fif_data.xlsx'))\n",
    "target_df=pd.read_excel(os.path.join(new_dir,'target.xlsx'))\n",
    "wenben_df=pd.read_excel(os.path.join(new_dir,mix_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62075d36-f9cf-4309-a201-1ef014f56cb4",
   "metadata": {},
   "source": [
    "# 4. 标准化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a093f0e5",
   "metadata": {},
   "source": [
    "## 4.1 历史数据标准化函数norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f00c73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(df):\n",
    "    x=df.copy()\n",
    "    open_mean_value = df['open'].mean(axis=0)\n",
    "    high_mean_value = df['high'].mean(axis=0)\n",
    "    low_mean_value = df['low'].mean()\n",
    "    close_mean_value = df['close'].mean()\n",
    "    volumerate_mean_value = df['volume_rate'].mean()\n",
    "\n",
    "    open_std_value = df['open'].std()\n",
    "    high_std_value = df['high'].std()\n",
    "    low_std_value = df['low'].std()\n",
    "    close_std_value = df['close'].std()\n",
    "    volumerate_std_value = df['volume_rate'].std()\n",
    "\n",
    "    x['open']=(df['open']-open_mean_value)/open_std_value\n",
    "    x['high'] = (df['high'] - high_mean_value) / high_std_value\n",
    "    x['low'] =  (df['low'] - low_mean_value) / low_std_value\n",
    "    x['close'] =  (df['close'] - close_mean_value) / close_std_value\n",
    "    x['volume_rate'] = (df['volume_rate'] - volumerate_mean_value) / volumerate_std_value\n",
    "    df=x\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a46668",
   "metadata": {},
   "source": [
    "## 4.2 文本数据标准化函数wenben_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78f471cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wenben_norm(df):\n",
    "    x=df.copy()\n",
    "    sector_score_mean_value = df['sector_score'].mean(axis=0)\n",
    "    search_index_mean_value = df['search_index'].mean(axis=0)\n",
    "\n",
    "    sector_score_std_value = df['sector_score'].std()\n",
    "    search_index_std_value = df['search_index'].std()\n",
    "\n",
    "    x['sector_score']=(df['sector_score']-sector_score_mean_value)/sector_score_std_value\n",
    "    x['search_index'] = (df['search_index'] - search_index_mean_value) / search_index_std_value\n",
    "    \n",
    "    df=x\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a82c845-6afe-43a1-820a-ae8b4e8fb2ab",
   "metadata": {},
   "source": [
    "# 5. 数据切分训练集与测试集"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6911e7",
   "metadata": {},
   "source": [
    "## 5.1 数据切分函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07835973",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(train_num=train_num,wenben_back=wenben_back):\n",
    "    \n",
    "    # 先切分\n",
    "    daily_train_df=daily_df.loc[daily_df.index<train_num]\n",
    "    daily_test_df=daily_df.loc[daily_df.index>=train_num]\n",
    "    \n",
    "    fif_train_df=fif_df.loc[fif_df.index<16*train_num]\n",
    "    fif_test_df=fif_df.loc[fif_df.index>=16*train_num]\n",
    "    \n",
    "    wenben_train_df=wenben_df.loc[wenben_df.index<train_num]\n",
    "    wenben_test_df=wenben_df.loc[wenben_df.index>=train_num]\n",
    "\n",
    "    target_train_df=target_df.loc[target_df.index<train_num]\n",
    "    target_test_df=target_df.loc[target_df.index>=train_num]\n",
    "\n",
    "    \n",
    "    #再进行归一化\n",
    "    daily_train_df=norm(daily_train_df)\n",
    "    daily_test_df=norm(daily_test_df)\n",
    "    fif_train_df=norm(fif_train_df)\n",
    "    fif_test_df=norm(fif_test_df)\n",
    "    wenben_train_df=wenben_norm(wenben_train_df)\n",
    "    wenben_test_df = wenben_norm(wenben_test_df)\n",
    "\n",
    "\n",
    "    return {'daily_train_df':daily_train_df,\n",
    "            'daily_test_df':daily_test_df,\n",
    "            'fif_train_df':fif_train_df,\n",
    "            'fif_test_df':fif_test_df,\n",
    "            'target_train_df':target_train_df,\n",
    "            'target_test_df':target_test_df,\n",
    "            'wenben_train_df':wenben_train_df,\n",
    "            'wenben_test_df': wenben_test_df\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557c115f",
   "metadata": {},
   "source": [
    "## 5.2 进行数据切分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b87cec91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "日频训练切分： (1295, 8)\n",
      "日频测试切分： (864, 8)\n",
      "十五分钟频训练切分： (20720, 6)\n",
      "十五分钟频测试切分： (14000, 6)\n",
      "训练目标切分： (1295, 2)\n",
      "测试目标切分： (875, 2)\n"
     ]
    }
   ],
   "source": [
    "daily_norm_train_df=split_data()['daily_train_df']\n",
    "print('日频训练切分：',daily_norm_train_df.shape)\n",
    "daily_norm_test_df=split_data()['daily_test_df']\n",
    "print('日频测试切分：',daily_norm_test_df.shape)\n",
    "fif_norm_train_df=split_data()['fif_train_df']\n",
    "print('十五分钟频训练切分：',fif_norm_train_df.shape)\n",
    "fif_norm_test_df=split_data()['fif_test_df']\n",
    "print('十五分钟频测试切分：',fif_norm_test_df.shape)\n",
    "target_norm_train_df=split_data()['target_train_df']\n",
    "print('训练目标切分：',target_norm_train_df.shape)\n",
    "target_norm_test_df=split_data()['target_test_df']\n",
    "print('测试目标切分：',target_norm_test_df.shape)\n",
    "wenben_norm_train_df=split_data()['wenben_train_df']\n",
    "wenben_norm_test_df=split_data()['wenben_test_df']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a225c99c-5d81-4930-8aa6-eda77400170e",
   "metadata": {},
   "source": [
    "# 6. 数据转化为神经网络输入格式"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffb3f1f-314a-4710-b96a-62d39be82ec6",
   "metadata": {},
   "source": [
    "## 6.1 建立转化类（返回多个字典）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de355a30-733f-4c79-978d-600334ad64dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data_maker:\n",
    "    def __init__(self,train_num,test_num,fif_back,daily_back,wenben_back):\n",
    "        self.train_num=train_num\n",
    "        self.test_num=test_num\n",
    "        self.fif_back=fif_back\n",
    "        self.daily_back=daily_back\n",
    "        self.wenben_back = wenben_back\n",
    "\n",
    "\n",
    "    def daily_train_data(self,data):\n",
    "        while True:\n",
    "            rows = list(range(self.train_num - self.daily_back)) #总共1650个数据，由于扣除前面20个数据，所以为1630\n",
    "            ### 先构造空（预测日长度*日后移）array\n",
    "            samples = np.zeros((len(rows),\n",
    "                                 self.daily_back,\n",
    "                                 5))\n",
    "            print(samples.shape)\n",
    "            for j in rows:\n",
    "                ### 每一个填入用于预测一天的开盘价到波动率矩阵\n",
    "                samples[j] = data.loc[\n",
    "                                  (data.index >= j) & (data.index < self.daily_back + j),\n",
    "                                  'open':'volume_rate']\n",
    "            print(data.index)\n",
    "            print('日频训练array：',samples.shape)\n",
    "            return samples\n",
    "    def fif_train_data(self,data):\n",
    "        while True:\n",
    "            rows = list(range(self.train_num - self.daily_back))\n",
    "            samples = np.zeros((len(rows),\n",
    "                                 self.fif_back,\n",
    "                                 5))\n",
    "            for j in rows:\n",
    "\n",
    "                samples[j] = data.loc[\n",
    "                              (data.index >= j * self.fif_back ) & (data.index < (j+1) * self.fif_back),\n",
    "                              'open':]\n",
    "            print('十五分钟训练array：',samples.shape)\n",
    "            return samples\n",
    "    def wenben_train_data(self,data):\n",
    "        while True:\n",
    "            rows = list(range(self.train_num - self.daily_back)) #总共1489个数据，由于扣除前面20个数据，所以为1469\n",
    "            samples = np.zeros((len(rows),\n",
    "                                 self.wenben_back,\n",
    "                                 wenben_sort))\n",
    "            for j in rows:\n",
    "\n",
    "                samples[j] = data.loc[\n",
    "                                  (data.index >= j) & (data.index < self.wenben_back + j),\n",
    "                                  first_columns:]\n",
    "            print('文本长期训练array：',samples.shape)\n",
    "            return samples\n",
    "   \n",
    "\n",
    "    def daily_test_data(self,data):\n",
    "        while True:\n",
    "            rows = list(range(self.test_num - self.daily_back))\n",
    "            print(self.test_num,self.daily_back)\n",
    "            print(rows)\n",
    "            samples = np.zeros((len(rows),\n",
    "                                self.daily_back,\n",
    "                                 5))\n",
    "            for j in rows:\n",
    "\n",
    "\n",
    "                samples[j] = data.loc[\n",
    "                                  (data.index >= self.train_num+j) & (data.index < self.train_num+self.daily_back + j),\n",
    "                                  'open':'volume_rate']\n",
    "            print('日测试array：',samples.shape)\n",
    "            print('试一试index', data.index,'train_num',self.train_num)\n",
    "            return samples\n",
    "\n",
    "    def wenben_test_data(self, data):\n",
    "        while True:\n",
    "            rows = list(range(self.test_num - self.daily_back))\n",
    "            samples = np.zeros((len(rows),\n",
    "                                self.wenben_back,\n",
    "                                wenben_sort))\n",
    "            for j in rows:\n",
    "                samples[j] = data.loc[\n",
    "                             (data.index >= self.train_num + j) & (data.index < self.train_num + self.wenben_back + j),\n",
    "                             first_columns:]\n",
    "            print('长期文本测试array：', samples.shape)\n",
    "            return samples\n",
    "   \n",
    "    def fif_test_data(self,data):\n",
    "        while True:\n",
    "            rows = list(range(self.test_num - self.daily_back))\n",
    "            samples = np.zeros((len(rows),\n",
    "                                self.fif_back,\n",
    "                                 5))\n",
    "            for j in rows:\n",
    "\n",
    "\n",
    "                samples[j] = data.loc[\n",
    "                                 (data.index >= 16*self.train_num+(j) * self.fif_back) & (data.index < 16*self.train_num+(j+1) * self.fif_back),\n",
    "                                 'open':]\n",
    "            print('十五分钟测试array：',samples.shape)\n",
    "            return samples\n",
    "    def target_train_data(self,data):\n",
    "        while True:\n",
    "            rows = list(range(self.train_num-self.daily_back))\n",
    "            targets = np.zeros((len(rows),))\n",
    "            for j in rows:\n",
    "\n",
    "\n",
    "                targets[j] = data.loc[data.index == j, 'target'].iloc[0] #根据提示，添加了.iloc[0]\n",
    "            print('训练标签array',targets.shape)\n",
    "            return targets\n",
    "    def target_test_data(self,data):\n",
    "        while True:\n",
    "            rows = list(range(self.test_num-self.daily_back))\n",
    "            targets = np.zeros((len(rows),))\n",
    "            for j in rows:\n",
    "\n",
    "\n",
    "                targets[j] = data.loc[data.index == self.train_num+j, 'target'].iloc[0] ##出问题：应该是。而不是***：data.index == self.train_num+j\n",
    "            print(targets.shape)\n",
    "            return targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d109eb0-7de5-414a-a276-f81fcefe1269",
   "metadata": {},
   "source": [
    "## 6.2 设置类方法里的参数，赋值给origin_data_maker，仍然是一个class类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e39a13e8-0b0d-4cb8-b630-a142d4529615",
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_data_maker=Data_maker(train_num=train_num,test_num=test_num,fif_back=16,daily_back=daily_back,wenben_back=wenben_back)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84200b8",
   "metadata": {},
   "source": [
    "# 6.3 调用类中的方法,处理原始数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a26f72f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1275, 20, 5)\n",
      "Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,\n",
      "       ...\n",
      "       1285, 1286, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1294],\n",
      "      dtype='int64', length=1295)\n",
      "日频训练array： (1275, 20, 5)\n",
      "864 20\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843]\n",
      "日测试array： (844, 20, 5)\n",
      "试一试index Index([1295, 1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1304,\n",
      "       ...\n",
      "       2149, 2150, 2151, 2152, 2153, 2154, 2155, 2156, 2157, 2158],\n",
      "      dtype='int64', length=864) train_num 1295\n",
      "十五分钟训练array： (1275, 16, 5)\n",
      "十五分钟测试array： (844, 16, 5)\n",
      "文本长期训练array： (1275, 10, 2)\n",
      "长期文本测试array： (844, 10, 2)\n",
      "训练标签array (1275,)\n",
      "(844,)\n"
     ]
    }
   ],
   "source": [
    "DM = origin_data_maker\n",
    "\n",
    "daily_train_prepared = DM.daily_train_data(daily_norm_train_df)\n",
    "daily_test_prepared = DM.daily_test_data(daily_norm_test_df)\n",
    "\n",
    "fif_train_prepared = DM.fif_train_data(fif_norm_train_df)\n",
    "fif_test_prepared = DM.fif_test_data(fif_norm_test_df)\n",
    "\n",
    "wenben_train_prepared = DM.wenben_train_data(wenben_norm_train_df)\n",
    "wenben_test_prepared = DM.wenben_test_data(wenben_norm_test_df)\n",
    "\n",
    "target_train_prepared = DM.target_train_data(target_norm_train_df)\n",
    "target_test_prepared = DM.target_test_data(target_norm_test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "082f7ca9-9c73-4357-95e4-b0639fc865cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# daily_train_prepared\n",
    "# daily_test_prepared\n",
    "\n",
    "# fif_train_prepared\n",
    "# fif_test_prepared \n",
    "\n",
    "# wenben_train_prepared\n",
    "# wenben_test_prepared\n",
    "\n",
    "# target_train_prepared\n",
    "# target_test_prepared"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb802e8a",
   "metadata": {},
   "source": [
    "# 7. 神经网络模型训练"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9ca801-990d-4205-a794-e3784edf76a1",
   "metadata": {},
   "source": [
    "## 7.1 模型建立 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f40a1c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def my_model(daily_back, LSTM_num, dense_num, learning_rate):\n",
    "    # 15分钟频输入\n",
    "    fif_min_input = Input(shape=(16, 5), dtype='float32', name='fif_min_input')\n",
    "    Conv1D_fif = layers.Conv1D(16, 1, strides=1)(fif_min_input)\n",
    "    LSTM_fif = layers.LSTM(LSTM_num)(Conv1D_fif)\n",
    "    \n",
    "    # 日频输入\n",
    "    daily_input = Input(shape=(daily_back, 5), dtype='float32', name='daily_input')\n",
    "    Conv1D_daily = layers.Conv1D(16, 1, strides=1)(daily_input)\n",
    "    LSTM_daily = layers.LSTM(LSTM_num)(Conv1D_daily)\n",
    "    \n",
    "    # 合并与全连接\n",
    "    concatenated = layers.concatenate([LSTM_fif, LSTM_daily], axis=-1)\n",
    "    alloy = layers.Dense(dense_num, activation='relu')(concatenated)\n",
    "    dropout = layers.Dropout(0.2)(alloy)\n",
    "    output = layers.Dense(1, activation='sigmoid')(dropout)\n",
    "    \n",
    "    model = Model([fif_min_input, daily_input], output)\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), \n",
    "                  loss='binary_crossentropy', \n",
    "                  metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d59d6ec-c99d-4d64-af71-5b7e777e4eae",
   "metadata": {},
   "source": [
    "# 创建早停机制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c87ecab-1d59-4ef6-a658-dc4c9ccae6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建早停回调\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',    # 监控验证集损失\n",
    "    patience=patience,           # 如果连续10个epoch验证集损失没有改善，则停止训练\n",
    "    restore_best_weights=True  # 恢复验证集损失最低时的模型权重\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cb0845-d365-4979-84d5-90540b299960",
   "metadata": {},
   "source": [
    "# 2. 定义适应度函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8dbc63ea-2505-488f-adc7-0a778f7879a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def fitness_function(params):\n",
    "    LSTM_num = int(params[0])\n",
    "    dense_num = int(params[1])\n",
    "    learning_rate = params[2]\n",
    "\n",
    "\n",
    "    \n",
    "    model = my_model(daily_back=daily_back,  # 替换为实际daily_back值\n",
    "                     LSTM_num=LSTM_num,\n",
    "                     dense_num=dense_num,\n",
    "                     learning_rate=learning_rate)\n",
    "    \n",
    "    history = model.fit(x=[fif_train_prepared,daily_train_prepared],y=target_train_prepared,batch_size=batch_size,\n",
    "                validation_split=0.25,epochs=epochs,callbacks=[early_stopping])\n",
    "    return history.history['val_loss'][-1]  # 返回验证损失（越小越好）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcb4aca-acf5-42c1-a3e3-a0146a1b4310",
   "metadata": {},
   "source": [
    "# 3. 实现麻雀搜索算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ffb38a63-5310-43c4-b7b7-6181f62e545f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparrow(pop_size, max_iter, dim, lower_bounds, upper_bounds, fitness_func):\n",
    "    pop = np.random.uniform(low=lower_bounds, high=upper_bounds, size=(pop_size, dim))\n",
    "    fitness = np.array([fitness_func(ind) for ind in pop])\n",
    "    best_idx = np.argmin(fitness)\n",
    "    best_sol = pop[best_idx].copy()\n",
    "    best_fit = fitness[best_idx]\n",
    "\n",
    "    for t in range(max_iter):\n",
    "        # 排序\n",
    "        sorted_idx = np.argsort(fitness)\n",
    "        pop = pop[sorted_idx]\n",
    "        fitness = fitness[sorted_idx]\n",
    "\n",
    "        # 发现者策略\n",
    "        for i in range(int(pop_size * 0.2)):\n",
    "            if np.random.rand() < 0.8:\n",
    "                pop[i] *= np.exp(-i / (np.random.rand() * max_iter))\n",
    "            else:\n",
    "                pop[i] += np.random.normal(0, 1)\n",
    "            \n",
    "            # 每次更新后立即检查边界\n",
    "            pop[i] = np.clip(pop[i], lower_bounds, upper_bounds)\n",
    "\n",
    "        # 跟随者策略 - 改进矩阵计算\n",
    "        for i in range(int(pop_size * 0.2), pop_size):\n",
    "            if i > pop_size / 2:\n",
    "                pop[i] = np.random.normal(0, 1) * np.exp((pop[-1] - pop[i]) / (i ** 2))\n",
    "            else:\n",
    "                # 简化矩阵计算，避免奇异矩阵问题\n",
    "                A = np.random.choice([-1, 1], size=dim)\n",
    "                pop[i] = pop[0] + A * (pop[0] - pop[i])\n",
    "            \n",
    "            # 每次更新后立即检查边界\n",
    "            pop[i] = np.clip(pop[i], lower_bounds, upper_bounds)\n",
    "\n",
    "        # 警戒者策略\n",
    "        for i in range(pop_size):\n",
    "            if fitness[i] > best_fit:\n",
    "                pop[i] = best_sol + np.random.normal(0, 1)\n",
    "                # 立即检查边界\n",
    "                pop[i] = np.clip(pop[i], lower_bounds, upper_bounds)\n",
    "\n",
    "        # 更新最佳解\n",
    "        fitness = np.array([fitness_func(ind) for ind in pop])\n",
    "        current_best_idx = np.argmin(fitness)\n",
    "        if fitness[current_best_idx] < best_fit:\n",
    "            best_fit = fitness[current_best_idx]\n",
    "            best_sol = pop[current_best_idx].copy()\n",
    "\n",
    "    return best_sol, best_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a102678-07e2-469d-9ec9-d9e8ca85b71a",
   "metadata": {},
   "source": [
    "# 4. 运行优化并训练最终模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fdda013f-3939-4290-af12-48381f4273d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - acc: 0.5408 - loss: 0.7265 - val_acc: 0.5423 - val_loss: 0.7315\n",
      "Epoch 2/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.5403 - loss: 0.6934 - val_acc: 0.5423 - val_loss: 0.6877\n",
      "Epoch 3/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.5328 - loss: 0.6877 - val_acc: 0.5674 - val_loss: 0.6892\n",
      "Epoch 4/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 0.5557 - loss: 0.6852 - val_acc: 0.5455 - val_loss: 0.7232\n",
      "Epoch 5/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 0.5693 - loss: 0.6763 - val_acc: 0.5423 - val_loss: 0.7010\n",
      "Epoch 6/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 0.5483 - loss: 0.6867 - val_acc: 0.5517 - val_loss: 0.7036\n",
      "Epoch 7/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 0.5700 - loss: 0.6776 - val_acc: 0.5580 - val_loss: 0.6906\n",
      "Epoch 8/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - acc: 0.5318 - loss: 0.6816 - val_acc: 0.5486 - val_loss: 0.7211\n",
      "Epoch 9/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - acc: 0.5518 - loss: 0.6834 - val_acc: 0.5517 - val_loss: 0.7006\n",
      "Epoch 10/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - acc: 0.5461 - loss: 0.6849 - val_acc: 0.5455 - val_loss: 0.7190\n",
      "Epoch 11/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - acc: 0.5785 - loss: 0.6765 - val_acc: 0.5235 - val_loss: 0.7173\n",
      "Epoch 12/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - acc: 0.5992 - loss: 0.6906 - val_acc: 0.5643 - val_loss: 0.7187\n",
      "Epoch 13/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - acc: 0.5805 - loss: 0.6820 - val_acc: 0.5486 - val_loss: 0.6942\n",
      "Epoch 14/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - acc: 0.5902 - loss: 0.6678 - val_acc: 0.4514 - val_loss: 0.7592\n",
      "Epoch 15/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 0.5456 - loss: 0.6974 - val_acc: 0.5486 - val_loss: 0.6996\n",
      "Epoch 16/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 0.5698 - loss: 0.6718 - val_acc: 0.5329 - val_loss: 0.6965\n",
      "Epoch 17/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 0.6310 - loss: 0.6624 - val_acc: 0.5580 - val_loss: 0.6935\n",
      "Epoch 18/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - acc: 0.5847 - loss: 0.6639 - val_acc: 0.5392 - val_loss: 0.6881\n",
      "Epoch 19/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - acc: 0.6162 - loss: 0.6656 - val_acc: 0.5329 - val_loss: 0.6850\n",
      "Epoch 20/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 0.5806 - loss: 0.6742 - val_acc: 0.5517 - val_loss: 0.7029\n",
      "Epoch 21/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 0.6049 - loss: 0.6567 - val_acc: 0.5266 - val_loss: 0.7027\n",
      "Epoch 22/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 0.5703 - loss: 0.6671 - val_acc: 0.5611 - val_loss: 0.6951\n",
      "Epoch 23/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - acc: 0.5525 - loss: 0.6735 - val_acc: 0.5580 - val_loss: 0.7206\n",
      "Epoch 24/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 0.5763 - loss: 0.6626 - val_acc: 0.5517 - val_loss: 0.7116\n",
      "Epoch 25/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 0.5945 - loss: 0.6590 - val_acc: 0.5486 - val_loss: 0.6858\n",
      "Epoch 26/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 0.5920 - loss: 0.6620 - val_acc: 0.5517 - val_loss: 0.7748\n",
      "Epoch 27/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 0.5901 - loss: 0.6664 - val_acc: 0.5580 - val_loss: 0.7112\n",
      "Epoch 28/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 0.6297 - loss: 0.6455 - val_acc: 0.5455 - val_loss: 0.7050\n",
      "Epoch 29/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 0.6244 - loss: 0.6585 - val_acc: 0.5423 - val_loss: 0.7294\n",
      "Epoch 30/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 0.6086 - loss: 0.6407 - val_acc: 0.5329 - val_loss: 0.7502\n",
      "Epoch 31/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 0.6611 - loss: 0.6227 - val_acc: 0.5204 - val_loss: 0.7009\n",
      "Epoch 32/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 0.6429 - loss: 0.6517 - val_acc: 0.5611 - val_loss: 0.7170\n",
      "Epoch 33/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 0.6261 - loss: 0.6298 - val_acc: 0.5799 - val_loss: 0.6902\n",
      "Epoch 34/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 0.6377 - loss: 0.6392 - val_acc: 0.5172 - val_loss: 0.9033\n",
      "Epoch 35/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 0.6265 - loss: 0.6255 - val_acc: 0.5392 - val_loss: 0.7182\n",
      "Epoch 36/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 0.6726 - loss: 0.5958 - val_acc: 0.5392 - val_loss: 0.9809\n",
      "Epoch 37/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - acc: 0.6602 - loss: 0.6058 - val_acc: 0.5517 - val_loss: 0.7551\n",
      "Epoch 38/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 0.6757 - loss: 0.5772 - val_acc: 0.5204 - val_loss: 0.8172\n",
      "Epoch 39/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 0.6683 - loss: 0.5778 - val_acc: 0.5486 - val_loss: 0.9227\n",
      "Epoch 40/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 0.7107 - loss: 0.5430 - val_acc: 0.5705 - val_loss: 0.9032\n",
      "Epoch 41/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 0.7295 - loss: 0.5363 - val_acc: 0.5549 - val_loss: 0.8097\n",
      "Epoch 42/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 0.6456 - loss: 0.6108 - val_acc: 0.5549 - val_loss: 0.7863\n",
      "Epoch 43/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 0.6806 - loss: 0.5697 - val_acc: 0.5392 - val_loss: 0.8459\n",
      "Epoch 44/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 0.7056 - loss: 0.5367 - val_acc: 0.5455 - val_loss: 0.7691\n",
      "Epoch 45/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 0.7213 - loss: 0.5247 - val_acc: 0.5298 - val_loss: 0.9089\n",
      "Epoch 46/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 0.7312 - loss: 0.5096 - val_acc: 0.5674 - val_loss: 0.9437\n",
      "Epoch 47/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - acc: 0.7373 - loss: 0.4807 - val_acc: 0.5486 - val_loss: 1.2916\n",
      "Epoch 48/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 0.7339 - loss: 0.4929 - val_acc: 0.5611 - val_loss: 1.0123\n",
      "Epoch 49/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 0.7485 - loss: 0.4871 - val_acc: 0.4859 - val_loss: 1.0327\n",
      "Epoch 50/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 0.7895 - loss: 0.4244 - val_acc: 0.5423 - val_loss: 1.1718\n",
      "Epoch 51/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 0.8110 - loss: 0.4037 - val_acc: 0.5361 - val_loss: 1.2531\n",
      "Epoch 52/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 0.7771 - loss: 0.4202 - val_acc: 0.5517 - val_loss: 1.0842\n",
      "Epoch 53/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 0.7818 - loss: 0.4515 - val_acc: 0.5549 - val_loss: 1.2328\n",
      "Epoch 54/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 0.7998 - loss: 0.4149 - val_acc: 0.6082 - val_loss: 1.0976\n",
      "Epoch 55/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 0.7912 - loss: 0.4212 - val_acc: 0.5423 - val_loss: 1.4835\n",
      "Epoch 56/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 0.7979 - loss: 0.3604 - val_acc: 0.5361 - val_loss: 1.3967\n",
      "Epoch 57/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 0.7819 - loss: 0.3945 - val_acc: 0.5611 - val_loss: 1.6200\n",
      "Epoch 58/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - acc: 0.8293 - loss: 0.3470 - val_acc: 0.5455 - val_loss: 1.4557\n",
      "Epoch 59/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 0.7718 - loss: 0.4196 - val_acc: 0.5580 - val_loss: 1.4213\n",
      "Epoch 60/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 0.8066 - loss: 0.3911 - val_acc: 0.5110 - val_loss: 1.8653\n",
      "Epoch 61/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 0.8314 - loss: 0.3451 - val_acc: 0.5486 - val_loss: 2.0534\n",
      "Epoch 62/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 0.8308 - loss: 0.3493 - val_acc: 0.5517 - val_loss: 1.4995\n",
      "Epoch 63/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 0.8252 - loss: 0.3272 - val_acc: 0.5455 - val_loss: 1.8222\n",
      "Epoch 64/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 0.8327 - loss: 0.3175 - val_acc: 0.5392 - val_loss: 1.8919\n",
      "Epoch 65/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 0.8756 - loss: 0.2795 - val_acc: 0.5172 - val_loss: 2.2343\n",
      "Epoch 66/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 0.7969 - loss: 0.3968 - val_acc: 0.5078 - val_loss: 2.1965\n",
      "Epoch 67/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - acc: 0.8192 - loss: 0.3946 - val_acc: 0.5298 - val_loss: 1.7894\n",
      "Epoch 68/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 0.7942 - loss: 0.3755 - val_acc: 0.5266 - val_loss: 1.6724\n",
      "Epoch 69/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 0.8600 - loss: 0.3296 - val_acc: 0.5549 - val_loss: 2.2117\n",
      "Epoch 70/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 0.8400 - loss: 0.3089 - val_acc: 0.5392 - val_loss: 2.1729\n",
      "Epoch 71/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 0.8818 - loss: 0.2772 - val_acc: 0.5298 - val_loss: 2.2402\n",
      "Epoch 72/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 0.8447 - loss: 0.3198 - val_acc: 0.5329 - val_loss: 1.7164\n",
      "Epoch 73/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 0.8639 - loss: 0.2904 - val_acc: 0.5549 - val_loss: 2.6116\n",
      "Epoch 74/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 0.8616 - loss: 0.3138 - val_acc: 0.5674 - val_loss: 1.6912\n",
      "Epoch 75/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - acc: 0.8706 - loss: 0.2575 - val_acc: 0.5361 - val_loss: 1.9527\n",
      "Epoch 76/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 0.9136 - loss: 0.2209 - val_acc: 0.5455 - val_loss: 2.3523\n",
      "Epoch 77/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 0.8849 - loss: 0.2613 - val_acc: 0.5517 - val_loss: 2.4158\n",
      "Epoch 78/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 0.8870 - loss: 0.2355 - val_acc: 0.5517 - val_loss: 2.5939\n",
      "Epoch 79/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 0.8744 - loss: 0.2729 - val_acc: 0.5298 - val_loss: 1.9769\n",
      "Epoch 80/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 0.8723 - loss: 0.2796 - val_acc: 0.5549 - val_loss: 2.3074\n",
      "Epoch 81/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 0.8962 - loss: 0.2299 - val_acc: 0.5235 - val_loss: 2.5967\n",
      "Epoch 82/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - acc: 0.9056 - loss: 0.2142 - val_acc: 0.5392 - val_loss: 2.4156\n",
      "Epoch 83/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - acc: 0.8977 - loss: 0.2251 - val_acc: 0.5423 - val_loss: 2.5055\n",
      "Epoch 84/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 0.8958 - loss: 0.2622 - val_acc: 0.5580 - val_loss: 2.2684\n",
      "Epoch 85/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 0.8392 - loss: 0.3124 - val_acc: 0.5392 - val_loss: 1.8938\n",
      "Epoch 86/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 0.8493 - loss: 0.3176 - val_acc: 0.5580 - val_loss: 2.0218\n",
      "Epoch 87/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 0.8648 - loss: 0.2846 - val_acc: 0.5298 - val_loss: 2.3205\n",
      "Epoch 88/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 0.8942 - loss: 0.2723 - val_acc: 0.5078 - val_loss: 2.3030\n",
      "Epoch 89/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 0.8862 - loss: 0.2690 - val_acc: 0.5486 - val_loss: 2.5307\n",
      "Epoch 90/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - acc: 0.8825 - loss: 0.2682 - val_acc: 0.4953 - val_loss: 2.5747\n",
      "Epoch 91/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 0.9209 - loss: 0.2223 - val_acc: 0.5266 - val_loss: 2.5431\n",
      "Epoch 92/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 0.9001 - loss: 0.2230 - val_acc: 0.5298 - val_loss: 2.7093\n",
      "Epoch 93/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - acc: 0.8848 - loss: 0.2370 - val_acc: 0.5392 - val_loss: 3.5195\n",
      "Epoch 94/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 0.8913 - loss: 0.2434 - val_acc: 0.5298 - val_loss: 2.6872\n",
      "Epoch 95/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 0.9295 - loss: 0.1880 - val_acc: 0.5361 - val_loss: 2.7664\n",
      "Epoch 96/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - acc: 0.9207 - loss: 0.1690 - val_acc: 0.5204 - val_loss: 3.0340\n",
      "Epoch 97/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 0.9226 - loss: 0.1661 - val_acc: 0.5329 - val_loss: 2.9810\n",
      "Epoch 98/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 0.9272 - loss: 0.1751 - val_acc: 0.5141 - val_loss: 2.7064\n",
      "Epoch 99/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 0.9165 - loss: 0.1813 - val_acc: 0.5392 - val_loss: 3.4754\n",
      "Epoch 100/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 0.9105 - loss: 0.1675 - val_acc: 0.5204 - val_loss: 3.5310\n",
      "Epoch 1/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - acc: 0.5064 - loss: 0.7175 - val_acc: 0.5329 - val_loss: 0.6882\n",
      "Epoch 2/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - acc: 0.5629 - loss: 0.6806 - val_acc: 0.5486 - val_loss: 0.6986\n",
      "Epoch 3/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - acc: 0.5368 - loss: 0.6885 - val_acc: 0.5423 - val_loss: 0.7393\n",
      "Epoch 4/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.5860 - loss: 0.6836 - val_acc: 0.5517 - val_loss: 0.6916\n",
      "Epoch 5/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - acc: 0.5475 - loss: 0.6823 - val_acc: 0.5423 - val_loss: 0.6819\n",
      "Epoch 6/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - acc: 0.5461 - loss: 0.6950 - val_acc: 0.5455 - val_loss: 0.7123\n",
      "Epoch 7/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - acc: 0.5710 - loss: 0.6740 - val_acc: 0.5486 - val_loss: 0.7051\n",
      "Epoch 8/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - acc: 0.5907 - loss: 0.6749 - val_acc: 0.5517 - val_loss: 0.6863\n",
      "Epoch 9/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - acc: 0.5685 - loss: 0.6789 - val_acc: 0.5580 - val_loss: 0.6973\n",
      "Epoch 10/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - acc: 0.5705 - loss: 0.6743 - val_acc: 0.5204 - val_loss: 0.6976\n",
      "Epoch 11/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - acc: 0.5939 - loss: 0.6621 - val_acc: 0.5580 - val_loss: 0.6902\n",
      "Epoch 12/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - acc: 0.6097 - loss: 0.6726 - val_acc: 0.5517 - val_loss: 0.6893\n",
      "Epoch 13/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - acc: 0.6024 - loss: 0.6670 - val_acc: 0.5298 - val_loss: 0.7069\n",
      "Epoch 14/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - acc: 0.5958 - loss: 0.6654 - val_acc: 0.5486 - val_loss: 0.7335\n",
      "Epoch 15/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - acc: 0.5952 - loss: 0.6611 - val_acc: 0.5361 - val_loss: 0.7663\n",
      "Epoch 16/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - acc: 0.6133 - loss: 0.6619 - val_acc: 0.5486 - val_loss: 0.7187\n",
      "Epoch 17/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - acc: 0.6036 - loss: 0.6558 - val_acc: 0.5705 - val_loss: 0.6898\n",
      "Epoch 18/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - acc: 0.5951 - loss: 0.6642 - val_acc: 0.5423 - val_loss: 0.7450\n",
      "Epoch 19/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - acc: 0.5961 - loss: 0.6633 - val_acc: 0.5517 - val_loss: 0.7138\n",
      "Epoch 20/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - acc: 0.5875 - loss: 0.6561 - val_acc: 0.5580 - val_loss: 0.7498\n",
      "Epoch 21/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - acc: 0.6337 - loss: 0.6511 - val_acc: 0.5611 - val_loss: 0.7122\n",
      "Epoch 22/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - acc: 0.6087 - loss: 0.6551 - val_acc: 0.5486 - val_loss: 0.7276\n",
      "Epoch 23/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - acc: 0.6227 - loss: 0.6326 - val_acc: 0.5549 - val_loss: 0.7725\n",
      "Epoch 24/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - acc: 0.6299 - loss: 0.6285 - val_acc: 0.5455 - val_loss: 0.8620\n",
      "Epoch 25/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.6277 - loss: 0.6499 - val_acc: 0.5486 - val_loss: 0.7367\n",
      "Epoch 26/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - acc: 0.6402 - loss: 0.6423 - val_acc: 0.5423 - val_loss: 0.7517\n",
      "Epoch 27/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - acc: 0.6033 - loss: 0.6411 - val_acc: 0.5423 - val_loss: 0.7467\n",
      "Epoch 28/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - acc: 0.6523 - loss: 0.6303 - val_acc: 0.5266 - val_loss: 0.7548\n",
      "Epoch 29/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - acc: 0.6334 - loss: 0.6385 - val_acc: 0.5549 - val_loss: 0.7489\n",
      "Epoch 30/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - acc: 0.6617 - loss: 0.6127 - val_acc: 0.5455 - val_loss: 0.7865\n",
      "Epoch 31/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - acc: 0.6365 - loss: 0.6194 - val_acc: 0.5549 - val_loss: 0.6939\n",
      "Epoch 32/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - acc: 0.6834 - loss: 0.5841 - val_acc: 0.5517 - val_loss: 0.7985\n",
      "Epoch 33/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - acc: 0.6871 - loss: 0.5714 - val_acc: 0.5580 - val_loss: 0.7429\n",
      "Epoch 34/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - acc: 0.6994 - loss: 0.5677 - val_acc: 0.5737 - val_loss: 0.7553\n",
      "Epoch 35/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - acc: 0.6892 - loss: 0.5764 - val_acc: 0.5517 - val_loss: 0.7505\n",
      "Epoch 36/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - acc: 0.7301 - loss: 0.5606 - val_acc: 0.5611 - val_loss: 0.7168\n",
      "Epoch 37/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - acc: 0.6965 - loss: 0.5779 - val_acc: 0.5298 - val_loss: 0.8494\n",
      "Epoch 38/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.6312 - loss: 0.6114 - val_acc: 0.5517 - val_loss: 0.7786\n",
      "Epoch 39/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - acc: 0.6973 - loss: 0.5549 - val_acc: 0.5517 - val_loss: 0.8205\n",
      "Epoch 40/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - acc: 0.7087 - loss: 0.5767 - val_acc: 0.5423 - val_loss: 0.8927\n",
      "Epoch 41/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - acc: 0.7393 - loss: 0.5326 - val_acc: 0.5643 - val_loss: 0.7566\n",
      "Epoch 42/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.7195 - loss: 0.5278 - val_acc: 0.5266 - val_loss: 0.8335\n",
      "Epoch 43/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - acc: 0.7162 - loss: 0.5798 - val_acc: 0.5266 - val_loss: 0.7922\n",
      "Epoch 44/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - acc: 0.6937 - loss: 0.5709 - val_acc: 0.5204 - val_loss: 0.8076\n",
      "Epoch 45/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.6869 - loss: 0.5424 - val_acc: 0.5799 - val_loss: 0.7958\n",
      "Epoch 46/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - acc: 0.7332 - loss: 0.5183 - val_acc: 0.5392 - val_loss: 0.8790\n",
      "Epoch 47/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.7316 - loss: 0.5091 - val_acc: 0.5831 - val_loss: 0.9576\n",
      "Epoch 48/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - acc: 0.7574 - loss: 0.5138 - val_acc: 0.5643 - val_loss: 0.8411\n",
      "Epoch 49/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - acc: 0.7628 - loss: 0.4746 - val_acc: 0.5423 - val_loss: 0.8873\n",
      "Epoch 50/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - acc: 0.7804 - loss: 0.4613 - val_acc: 0.5549 - val_loss: 0.8952\n",
      "Epoch 51/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - acc: 0.7754 - loss: 0.4646 - val_acc: 0.5768 - val_loss: 0.9389\n",
      "Epoch 52/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - acc: 0.7713 - loss: 0.4559 - val_acc: 0.5235 - val_loss: 0.8648\n",
      "Epoch 53/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - acc: 0.7779 - loss: 0.4477 - val_acc: 0.5611 - val_loss: 0.9198\n",
      "Epoch 54/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - acc: 0.7942 - loss: 0.4441 - val_acc: 0.5392 - val_loss: 1.0644\n",
      "Epoch 55/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - acc: 0.7788 - loss: 0.4329 - val_acc: 0.5423 - val_loss: 0.9768\n",
      "Epoch 56/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - acc: 0.7822 - loss: 0.4491 - val_acc: 0.5361 - val_loss: 1.0011\n",
      "Epoch 57/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - acc: 0.8086 - loss: 0.4263 - val_acc: 0.5768 - val_loss: 0.9365\n",
      "Epoch 58/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - acc: 0.7912 - loss: 0.4325 - val_acc: 0.5266 - val_loss: 0.9941\n",
      "Epoch 59/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - acc: 0.8046 - loss: 0.4120 - val_acc: 0.5737 - val_loss: 1.1891\n",
      "Epoch 60/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - acc: 0.7900 - loss: 0.4051 - val_acc: 0.5172 - val_loss: 1.1561\n",
      "Epoch 61/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - acc: 0.8029 - loss: 0.3926 - val_acc: 0.5643 - val_loss: 1.1931\n",
      "Epoch 62/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - acc: 0.8295 - loss: 0.3604 - val_acc: 0.5705 - val_loss: 1.2181\n",
      "Epoch 63/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - acc: 0.8147 - loss: 0.4087 - val_acc: 0.5172 - val_loss: 1.3641\n",
      "Epoch 64/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.8114 - loss: 0.3942 - val_acc: 0.5455 - val_loss: 1.1629\n",
      "Epoch 65/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - acc: 0.8386 - loss: 0.3646 - val_acc: 0.5110 - val_loss: 1.2666\n",
      "Epoch 66/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.8687 - loss: 0.3300 - val_acc: 0.5423 - val_loss: 1.3762\n",
      "Epoch 67/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - acc: 0.8449 - loss: 0.3342 - val_acc: 0.5486 - val_loss: 1.3715\n",
      "Epoch 68/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - acc: 0.8514 - loss: 0.3256 - val_acc: 0.5580 - val_loss: 1.3436\n",
      "Epoch 69/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.8252 - loss: 0.3415 - val_acc: 0.5110 - val_loss: 1.5545\n",
      "Epoch 70/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - acc: 0.8526 - loss: 0.3074 - val_acc: 0.5455 - val_loss: 1.5972\n",
      "Epoch 71/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - acc: 0.8780 - loss: 0.3093 - val_acc: 0.5455 - val_loss: 1.5545\n",
      "Epoch 72/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - acc: 0.8826 - loss: 0.2897 - val_acc: 0.5361 - val_loss: 1.4710\n",
      "Epoch 73/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - acc: 0.8737 - loss: 0.2650 - val_acc: 0.5235 - val_loss: 1.6168\n",
      "Epoch 74/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - acc: 0.8886 - loss: 0.2611 - val_acc: 0.5611 - val_loss: 1.5595\n",
      "Epoch 75/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - acc: 0.8895 - loss: 0.2656 - val_acc: 0.5110 - val_loss: 1.8387\n",
      "Epoch 76/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - acc: 0.8461 - loss: 0.3277 - val_acc: 0.5110 - val_loss: 1.7209\n",
      "Epoch 77/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - acc: 0.9006 - loss: 0.2336 - val_acc: 0.5172 - val_loss: 1.8143\n",
      "Epoch 78/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - acc: 0.9218 - loss: 0.2022 - val_acc: 0.5298 - val_loss: 2.0408\n",
      "Epoch 79/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - acc: 0.8833 - loss: 0.2496 - val_acc: 0.5423 - val_loss: 1.9305\n",
      "Epoch 80/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - acc: 0.9020 - loss: 0.2268 - val_acc: 0.5549 - val_loss: 1.8526\n",
      "Epoch 81/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - acc: 0.9161 - loss: 0.2174 - val_acc: 0.5486 - val_loss: 2.1598\n",
      "Epoch 82/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - acc: 0.8770 - loss: 0.2610 - val_acc: 0.5361 - val_loss: 1.8346\n",
      "Epoch 83/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - acc: 0.8715 - loss: 0.2560 - val_acc: 0.5737 - val_loss: 1.8285\n",
      "Epoch 84/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - acc: 0.8914 - loss: 0.2416 - val_acc: 0.5298 - val_loss: 1.8881\n",
      "Epoch 85/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9013 - loss: 0.2206 - val_acc: 0.5549 - val_loss: 2.0002\n",
      "Epoch 86/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9236 - loss: 0.1904 - val_acc: 0.5486 - val_loss: 1.9251\n",
      "Epoch 87/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9276 - loss: 0.1819 - val_acc: 0.5486 - val_loss: 2.1958\n",
      "Epoch 88/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - acc: 0.9224 - loss: 0.1638 - val_acc: 0.5423 - val_loss: 2.1554\n",
      "Epoch 89/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - acc: 0.9504 - loss: 0.1508 - val_acc: 0.5204 - val_loss: 2.1388\n",
      "Epoch 90/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9322 - loss: 0.1595 - val_acc: 0.5392 - val_loss: 2.0876\n",
      "Epoch 91/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - acc: 0.9265 - loss: 0.1491 - val_acc: 0.5361 - val_loss: 2.1044\n",
      "Epoch 92/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - acc: 0.9156 - loss: 0.1971 - val_acc: 0.5235 - val_loss: 2.0713\n",
      "Epoch 93/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - acc: 0.9051 - loss: 0.2199 - val_acc: 0.5455 - val_loss: 1.8887\n",
      "Epoch 94/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9385 - loss: 0.1704 - val_acc: 0.5423 - val_loss: 2.2153\n",
      "Epoch 95/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - acc: 0.9515 - loss: 0.1416 - val_acc: 0.5392 - val_loss: 2.3249\n",
      "Epoch 96/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9543 - loss: 0.1163 - val_acc: 0.5235 - val_loss: 2.7932\n",
      "Epoch 97/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - acc: 0.9599 - loss: 0.0958 - val_acc: 0.5392 - val_loss: 2.6085\n",
      "Epoch 98/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9696 - loss: 0.0974 - val_acc: 0.5549 - val_loss: 2.8491\n",
      "Epoch 99/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - acc: 0.9565 - loss: 0.1120 - val_acc: 0.5298 - val_loss: 2.7349\n",
      "Epoch 100/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - acc: 0.9601 - loss: 0.1106 - val_acc: 0.5172 - val_loss: 2.8317\n",
      "Epoch 1/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - acc: 0.4942 - loss: 0.7723 - val_acc: 0.5423 - val_loss: 0.6987\n",
      "Epoch 2/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - acc: 0.5450 - loss: 0.6895 - val_acc: 0.5455 - val_loss: 0.6889\n",
      "Epoch 3/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - acc: 0.5252 - loss: 0.7055 - val_acc: 0.5423 - val_loss: 0.6974\n",
      "Epoch 4/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - acc: 0.5343 - loss: 0.6869 - val_acc: 0.5455 - val_loss: 0.6994\n",
      "Epoch 5/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - acc: 0.5639 - loss: 0.6839 - val_acc: 0.5423 - val_loss: 0.7202\n",
      "Epoch 6/100\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - acc: 0.5658 - loss: 0.6766"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m pop_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m      5\u001b[0m max_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[0;32m----> 7\u001b[0m best_params, best_fitness \u001b[38;5;241m=\u001b[39m\u001b[43msparrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpop_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlower_bounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupper_bounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfitness_function\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m最佳参数：LSTM_num=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mint\u001b[39m(best_params[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, dense_num=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mint\u001b[39m(best_params[\u001b[38;5;241m1\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, learning_rate=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_params[\u001b[38;5;241m2\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m最佳验证准确率：\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_fitness\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[14], line 3\u001b[0m, in \u001b[0;36msparrow\u001b[0;34m(pop_size, max_iter, dim, lower_bounds, upper_bounds, fitness_func)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msparrow\u001b[39m(pop_size, max_iter, dim, lower_bounds, upper_bounds, fitness_func):\n\u001b[1;32m      2\u001b[0m     pop \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39muniform(low\u001b[38;5;241m=\u001b[39mlower_bounds, high\u001b[38;5;241m=\u001b[39mupper_bounds, size\u001b[38;5;241m=\u001b[39m(pop_size, dim))\n\u001b[0;32m----> 3\u001b[0m     fitness \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([fitness_func(ind) \u001b[38;5;28;01mfor\u001b[39;00m ind \u001b[38;5;129;01min\u001b[39;00m pop])\n\u001b[1;32m      4\u001b[0m     best_idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmin(fitness)\n\u001b[1;32m      5\u001b[0m     best_sol \u001b[38;5;241m=\u001b[39m pop[best_idx]\u001b[38;5;241m.\u001b[39mcopy()\n",
      "Cell \u001b[0;32mIn[14], line 3\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msparrow\u001b[39m(pop_size, max_iter, dim, lower_bounds, upper_bounds, fitness_func):\n\u001b[1;32m      2\u001b[0m     pop \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39muniform(low\u001b[38;5;241m=\u001b[39mlower_bounds, high\u001b[38;5;241m=\u001b[39mupper_bounds, size\u001b[38;5;241m=\u001b[39m(pop_size, dim))\n\u001b[0;32m----> 3\u001b[0m     fitness \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[43mfitness_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mind\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m ind \u001b[38;5;129;01min\u001b[39;00m pop])\n\u001b[1;32m      4\u001b[0m     best_idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmin(fitness)\n\u001b[1;32m      5\u001b[0m     best_sol \u001b[38;5;241m=\u001b[39m pop[best_idx]\u001b[38;5;241m.\u001b[39mcopy()\n",
      "Cell \u001b[0;32mIn[13], line 13\u001b[0m, in \u001b[0;36mfitness_function\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m      6\u001b[0m learning_rate \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m      8\u001b[0m model \u001b[38;5;241m=\u001b[39m my_model(daily_back\u001b[38;5;241m=\u001b[39mdaily_back,  \u001b[38;5;66;03m# 替换为实际daily_back值\u001b[39;00m\n\u001b[1;32m      9\u001b[0m                  LSTM_num\u001b[38;5;241m=\u001b[39mLSTM_num,\n\u001b[1;32m     10\u001b[0m                  dense_num\u001b[38;5;241m=\u001b[39mdense_num,\n\u001b[1;32m     11\u001b[0m                  learning_rate\u001b[38;5;241m=\u001b[39mlearning_rate)\n\u001b[0;32m---> 13\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mfif_train_prepared\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdaily_train_prepared\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_train_prepared\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.25\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/miniforge3/envs/tf_env/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniforge3/envs/tf_env/lib/python3.9/site-packages/keras/src/backend/tensorflow/trainer.py:372\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    370\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m    371\u001b[0m logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[0;32m--> 372\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/tf_env/lib/python3.9/site-packages/keras/src/callbacks/callback_list.py:172\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_async_dispatch(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_on_train_batch_end, batch, logs)\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 172\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_on_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/tf_env/lib/python3.9/site-packages/keras/src/callbacks/callback_list.py:194\u001b[0m, in \u001b[0;36mCallbackList._on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    192\u001b[0m logs \u001b[38;5;241m=\u001b[39m python_utils\u001b[38;5;241m.\u001b[39mpythonify_logs(logs)\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[0;32m--> 194\u001b[0m     \u001b[43mcallback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/tf_env/lib/python3.9/site-packages/keras/src/callbacks/progbar_logger.py:58\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mon_train_batch_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m---> 58\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_progbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/tf_env/lib/python3.9/site-packages/keras/src/callbacks/progbar_logger.py:95\u001b[0m, in \u001b[0;36mProgbarLogger._update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen \u001b[38;5;241m=\u001b[39m batch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# One-indexed.\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 95\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprogbar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinalize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/tf_env/lib/python3.9/site-packages/keras/src/utils/progbar.py:182\u001b[0m, in \u001b[0;36mProgbar.update\u001b[0;34m(self, current, values, finalize)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m finalize:\n\u001b[1;32m    180\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 182\u001b[0m \u001b[43mio_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprint_msg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mline_break\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prev_total_width \u001b[38;5;241m=\u001b[39m total_width\n\u001b[1;32m    184\u001b[0m message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/miniforge3/envs/tf_env/lib/python3.9/site-packages/keras/src/utils/io_utils.py:98\u001b[0m, in \u001b[0;36mprint_msg\u001b[0;34m(message, line_break)\u001b[0m\n\u001b[1;32m     96\u001b[0m message \u001b[38;5;241m=\u001b[39m message \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m line_break \u001b[38;5;28;01melse\u001b[39;00m message\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 98\u001b[0m     \u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstdout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mUnicodeEncodeError\u001b[39;00m:\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;66;03m# If the encoding differs from UTF-8, `sys.stdout.write` may fail.\u001b[39;00m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;66;03m# To address this, replace special unicode characters in the\u001b[39;00m\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;66;03m# message, and then encode and decode using the target encoding.\u001b[39;00m\n\u001b[1;32m    103\u001b[0m     message \u001b[38;5;241m=\u001b[39m _replace_special_unicode_character(message)\n",
      "File \u001b[0;32m~/miniforge3/envs/tf_env/lib/python3.9/site-packages/ipykernel/iostream.py:694\u001b[0m, in \u001b[0;36mOutStream.write\u001b[0;34m(self, string)\u001b[0m\n\u001b[1;32m    692\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpub_thread\u001b[38;5;241m.\u001b[39mschedule(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flush)\n\u001b[1;32m    693\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 694\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_schedule_flush\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(string)\n",
      "File \u001b[0;32m~/miniforge3/envs/tf_env/lib/python3.9/site-packages/ipykernel/iostream.py:590\u001b[0m, in \u001b[0;36mOutStream._schedule_flush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    587\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_schedule_in_thread\u001b[39m():\n\u001b[1;32m    588\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_io_loop\u001b[38;5;241m.\u001b[39mcall_later(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflush_interval, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flush)\n\u001b[0;32m--> 590\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpub_thread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mschedule\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_schedule_in_thread\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/tf_env/lib/python3.9/site-packages/ipykernel/iostream.py:267\u001b[0m, in \u001b[0;36mIOPubThread.schedule\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_events\u001b[38;5;241m.\u001b[39mappend(f)\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;66;03m# wake event thread (message content is ignored)\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_event_pipe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    269\u001b[0m     f()\n",
      "File \u001b[0;32m~/miniforge3/envs/tf_env/lib/python3.9/site-packages/zmq/sugar/socket.py:707\u001b[0m, in \u001b[0;36mSocket.send\u001b[0;34m(self, data, flags, copy, track, routing_id, group)\u001b[0m\n\u001b[1;32m    700\u001b[0m         data \u001b[38;5;241m=\u001b[39m zmq\u001b[38;5;241m.\u001b[39mFrame(\n\u001b[1;32m    701\u001b[0m             data,\n\u001b[1;32m    702\u001b[0m             track\u001b[38;5;241m=\u001b[39mtrack,\n\u001b[1;32m    703\u001b[0m             copy\u001b[38;5;241m=\u001b[39mcopy \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    704\u001b[0m             copy_threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy_threshold,\n\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m     data\u001b[38;5;241m.\u001b[39mgroup \u001b[38;5;241m=\u001b[39m group\n\u001b[0;32m--> 707\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrack\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m_zmq.py:1092\u001b[0m, in \u001b[0;36mzmq.backend.cython._zmq.Socket.send\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_zmq.py:1140\u001b[0m, in \u001b[0;36mzmq.backend.cython._zmq.Socket.send\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_zmq.py:1339\u001b[0m, in \u001b[0;36mzmq.backend.cython._zmq._send_copy\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_zmq.py:160\u001b[0m, in \u001b[0;36mzmq.backend.cython._zmq._check_rc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 超参数范围（LSTM_num, dense_num, learning_rate）\n",
    "lower_bounds = [64, 16, 1e-4]\n",
    "upper_bounds = [256, 64, 1e-2]\n",
    "pop_size = 10\n",
    "max_iter = 5\n",
    "\n",
    "best_params, best_fitness =sparrow(pop_size, max_iter, 3, lower_bounds, upper_bounds, fitness_function)\n",
    "\n",
    "print(f\"最佳参数：LSTM_num={int(best_params[0])}, dense_num={int(best_params[1])}, learning_rate={best_params[2]}\")\n",
    "print(f\"最佳验证准确率：{best_fitness}\")\n",
    "\n",
    "\n",
    "# 用最佳参数训练最终模型\n",
    "final_model = my_model(daily_back=daily_back,  # 替换为实际值\n",
    "                       LSTM_num=int(best_params[0]),\n",
    "                       dense_num=int(best_params[1]),\n",
    "                       learning_rate=best_params[2])\n",
    "final_model.fit(x=[fif_train_prepared,daily_train_prepared],y=target_train_prepared,batch_size=batch_size,\n",
    "                validation_split=0.25,epochs=epochs,callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a065f8c",
   "metadata": {},
   "source": [
    "## 7.2 模型滞后时长赋值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993a90eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model=my_model(daily_back=daily_back)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e025ba5e-a33c-4474-9138-18ad1474565b",
   "metadata": {},
   "source": [
    "## 7.3 添加输出模型参数的代码块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42bfef1-b9f0-4103-9a4d-c90f8bb13126",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(final_model, to_file='model_structure.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8620eccf",
   "metadata": {},
   "source": [
    "## 7.4 model.fit(输入训练数据x，标志y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebf83ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "history = final_model.fit(x=[fif_train_prepared,daily_train_prepared],y=target_train_prepared,\n",
    "                          batch_size=batch_size,validation_split=0.25,epochs=epochs,callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd0ae96",
   "metadata": {},
   "source": [
    "## 7.5 model.evaluate(输入测试数据)，进行模型预测性能测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bd90e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss,accuracy = final_model.evaluate([fif_test_prepared,daily_test_prepared],y=target_test_prepared)\n",
    "print(loss,accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62e60b0-7dc9-47e4-b131-df7a159dbf01",
   "metadata": {},
   "source": [
    "# 8. 回测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9607cca",
   "metadata": {},
   "source": [
    "# 构建y的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc23d49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_y_pred():\n",
    "    y_predict=final_model.predict([fif_test_prepared,daily_test_prepared],batch_size=1).reshape(test_num-daily_back).tolist() ###batch_size要设为1，不然evaluate和predict结果不同\n",
    "    y_pred=[]\n",
    "    for i,v in enumerate(y_predict):\n",
    "        if v>0.5:\n",
    "            y_pred.append(1)\n",
    "        if v<0.5:\n",
    "            y_pred.append(0)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915e4535",
   "metadata": {},
   "source": [
    "# 制作y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191b4fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=gen_y_pred()\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0f800a",
   "metadata": {},
   "source": [
    "#  构建使用测试集作为回测数据的类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c753f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Back_tes_trader:\n",
    "    def __init__(self,train_num,daily_back):\n",
    "        self.train_num=train_num\n",
    "        self.daily_back=daily_back\n",
    "    def daily_test_data(self,data):\n",
    "        while True:\n",
    "            samples = data.loc[\n",
    "                data.index >=self.train_num+self.daily_back ,\n",
    "                ['open','close']]\n",
    "            print(data.index)\n",
    "            return samples\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8bb8f4",
   "metadata": {},
   "source": [
    "# 回测数据集代入参数，形成回撤数据back_tes_trader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9555c139",
   "metadata": {},
   "outputs": [],
   "source": [
    "back_tes_trader=Back_tes_trader(train_num=train_num,daily_back=daily_back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b72e4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_back_trader(train_num=train_num):\n",
    "\n",
    "    daily_test_df=daily_df.loc[daily_df.index>=train_num]\n",
    "\n",
    "    return {'daily_test_df':daily_test_df}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0caaf456",
   "metadata": {},
   "outputs": [],
   "source": [
    "back_df=split_back_trader()['daily_test_df']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff686572",
   "metadata": {},
   "outputs": [],
   "source": [
    "back_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd75b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "backtrader_df=back_tes_trader.daily_test_data(back_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8c3651",
   "metadata": {},
   "source": [
    "# 形成day_rate_of_return日内收益率，和rate_of_return隔夜收益率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84028e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "backtrader_df['rate_of_return'] = backtrader_df['close'].rolling(2).apply(lambda x: x[1] / x[0] - 1, raw=True)\n",
    "backtrader_df['day_rate_of_return']=backtrader_df['close']/backtrader_df['open']-1\n",
    "\n",
    "clo_1=backtrader_df.loc[(backtrader_df.index<total_day-1),\"close\"].tolist()\n",
    "\n",
    "print(len(clo_1))\n",
    "print(backtrader_df.loc[(backtrader_df.index>=train_num+daily_back+1),:])\n",
    "backtrader_df.loc[(backtrader_df.index>=train_num+daily_back+1),'last_close']=clo_1\n",
    "backtrader_df['sale_rate_of_return']=backtrader_df['open']/backtrader_df['last_close']-1\n",
    "\n",
    "\n",
    "print(backtrader_df)\n",
    "print(backtrader_df.shape)\n",
    "trade_day_return_list=[]\n",
    "return_list=[]\n",
    "every_day_return_list=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94506474",
   "metadata": {},
   "source": [
    "# 回测交易逻辑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2a5071",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtrader(list,df):\n",
    "    a=0\n",
    "\n",
    "    rate_of_return = 1\n",
    "    for i,v in enumerate(list):\n",
    "        if (v ==1)&(a==0):\n",
    "            b=(1 + df.loc[train_num+daily_back + i, 'day_rate_of_return'])\n",
    "            rate_of_return= rate_of_return * b\n",
    "            a=1\n",
    "            trade_day_return_list.append(b-1)\n",
    "            return_list.append(rate_of_return)\n",
    "            every_day_return_list.append(b - 1)\n",
    "\n",
    "        elif (v ==1)&(a==1):\n",
    "            b=(1 + df.loc[train_num+daily_back + i, 'rate_of_return'])\n",
    "            rate_of_return= rate_of_return *b\n",
    "            a=a\n",
    "            trade_day_return_list.append(b-1)\n",
    "            return_list.append(rate_of_return)\n",
    "            every_day_return_list.append(b - 1)\n",
    "        elif (v==0)&(a==0):\n",
    "            rate_of_return=rate_of_return\n",
    "            a=a\n",
    "            every_day_return_list.append(0)\n",
    "\n",
    "        elif (v==0)&(a==1):\n",
    "            a=0\n",
    "            b = (1 + df.loc[train_num+daily_back + i, 'sale_rate_of_return'])\n",
    "            rate_of_return=rate_of_return*b\n",
    "            trade_day_return_list.append(b-1)\n",
    "            every_day_return_list.append(b - 1)\n",
    "            return_list.append(rate_of_return)\n",
    "    return a,trade_day_return_list,rate_of_return,return_list,every_day_return_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a6e92b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eda96a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "result=backtrader(y_pred,backtrader_df)\n",
    "# print(result[1])\n",
    "# print(result[2])\n",
    "# print(result[3])\n",
    "pingjun_nian_jiaoyi_ri=240*len(result[1])/(len(y_pred))\n",
    "sharp=(np.mean(result[1]))/(np.std(result[1],ddof=1))*np.sqrt(pingjun_nian_jiaoyi_ri)\n",
    "# sharp1=(np.mean(result[4]))/(np.std(result[4]))\n",
    "# print('夏普比率--：',sharp1)\n",
    "print('夏普比率：',sharp)\n",
    "print('收益率：',result[2]-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2ded5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e894d8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "returns=result[3]\n",
    "returns = [ret - 1 for ret in returns]\n",
    "# returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c359f589",
   "metadata": {},
   "outputs": [],
   "source": [
    "returns=result[3]\n",
    "returns = [ret - 1 for ret in returns]\n",
    "\n",
    "# 将收益率列表转换为pandas的Series对象，方便处理\n",
    "returns_series = pd.Series(returns)\n",
    "\n",
    "# 计算累计收益率\n",
    "cumulative_returns = (1 + returns_series).cumprod() - 1\n",
    "\n",
    "# 计算滚动最大值\n",
    "rolling_max = cumulative_returns.cummax()\n",
    "\n",
    "# 计算回撤\n",
    "drawdown = cumulative_returns - rolling_max\n",
    "\n",
    "# 计算最大回撤\n",
    "max_drawdown = drawdown.min()\n",
    "\n",
    "# 打印最大回撤\n",
    "print(\"最大回撤: {:.2%}\".format(max_drawdown))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d346e244",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb03bdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def paint():\n",
    "    acc=history.history['acc']\n",
    "    val_acc=history.history['val_acc']\n",
    "    loss=history.history['loss']\n",
    "    val_loss=history.history['val_loss']\n",
    "\n",
    "    epochs=range(len(acc))\n",
    "    plt.plot(epochs,acc,'bo',label='Training acc')\n",
    "    plt.plot(epochs,val_acc,'b',label='Validation acc')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.figure()\n",
    "\n",
    "    plt.plot(epochs,loss,'bo',label='Training loss')\n",
    "    plt.plot(epochs,val_loss,'b',label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()\n",
    "    return plt\n",
    "my_paint=paint()\n",
    "my_paint.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff449cf1",
   "metadata": {},
   "source": [
    "# 混淆矩阵绘制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2eaf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = confusion_matrix(target_test_prepared, y_pred,labels=[1,0])\n",
    "precision_score=precision_score(target_test_prepared, y_pred)\n",
    "recall_score=recall_score(target_test_prepared, y_pred)\n",
    "f1_score=f1_score(target_test_prepared, y_pred)\n",
    "\n",
    "print('混淆矩阵：',confusion_matrix)\n",
    "print('查准率：',precision_score)\n",
    "print('查全率：',recall_score)\n",
    "print('f1-score:',f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52941452",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict=final_model.predict([fif_test_prepared,daily_test_prepared]).reshape(test_num-daily_back).tolist()\n",
    "fpr,tpr,threshold = roc_curve(target_test_prepared, y_predict) ###计算真正率和假正率\n",
    "# print(fpr,tpr,threshold)\n",
    "roc_auc = auc(fpr,tpr)\n",
    "\n",
    "\n",
    "lw = 2\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc) ###假正率为横坐标，真正率为纵坐标做曲线\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302466a8",
   "metadata": {},
   "source": [
    "# 保存"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "tf_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
