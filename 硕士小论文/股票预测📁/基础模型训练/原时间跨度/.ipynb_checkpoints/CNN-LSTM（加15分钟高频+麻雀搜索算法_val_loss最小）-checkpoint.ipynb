{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49f433dd-af84-4c82-b8e3-1d4950fbdf36",
   "metadata": {},
   "source": [
    "# 1. 导入python库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f02e0e4-772a-47f3-bbd7-68372bf70654",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, recall_score, precision_score, f1_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa353efb",
   "metadata": {},
   "source": [
    "# 2. 参数设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccfe2d2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "daily_back=20\n",
    "wenben_back=10\n",
    "\n",
    "wenben_sort=2\n",
    "\n",
    "batch_size=32\n",
    "epochs=20\n",
    "\n",
    "# LSTM_num=100\n",
    "# dense_num=20\n",
    "\n",
    "\n",
    "mix_file='daily_data.xlsx'\n",
    "first_columns='search_index'\n",
    "\n",
    "\n",
    "total_day=2159 #根据查看数据表，得到数值\n",
    "train_num=1295\n",
    "test_num=total_day-train_num"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1006d29e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "08c9b0fa",
   "metadata": {},
   "source": [
    "# 3. 读取原始数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5a53a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dir='/Users/ccmac/Desktop/完成SCI数据'\n",
    "\n",
    "\n",
    "daily_df=pd.read_excel(os.path.join(new_dir,mix_file))\n",
    "fif_df=pd.read_excel(os.path.join(new_dir,'fif_data.xlsx'))\n",
    "target_df=pd.read_excel(os.path.join(new_dir,'target.xlsx'))\n",
    "wenben_df=pd.read_excel(os.path.join(new_dir,mix_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62075d36-f9cf-4309-a201-1ef014f56cb4",
   "metadata": {},
   "source": [
    "# 4. 标准化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a093f0e5",
   "metadata": {},
   "source": [
    "## 4.1 历史数据标准化函数norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f00c73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(df):\n",
    "    x=df.copy()\n",
    "    open_mean_value = df['open'].mean(axis=0)\n",
    "    high_mean_value = df['high'].mean(axis=0)\n",
    "    low_mean_value = df['low'].mean()\n",
    "    close_mean_value = df['close'].mean()\n",
    "    volumerate_mean_value = df['volume_rate'].mean()\n",
    "\n",
    "    open_std_value = df['open'].std()\n",
    "    high_std_value = df['high'].std()\n",
    "    low_std_value = df['low'].std()\n",
    "    close_std_value = df['close'].std()\n",
    "    volumerate_std_value = df['volume_rate'].std()\n",
    "\n",
    "    x['open']=(df['open']-open_mean_value)/open_std_value\n",
    "    x['high'] = (df['high'] - high_mean_value) / high_std_value\n",
    "    x['low'] =  (df['low'] - low_mean_value) / low_std_value\n",
    "    x['close'] =  (df['close'] - close_mean_value) / close_std_value\n",
    "    x['volume_rate'] = (df['volume_rate'] - volumerate_mean_value) / volumerate_std_value\n",
    "    df=x\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a46668",
   "metadata": {},
   "source": [
    "## 4.2 文本数据标准化函数wenben_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78f471cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wenben_norm(df):\n",
    "    x=df.copy()\n",
    "    sector_score_mean_value = df['sector_score'].mean(axis=0)\n",
    "    search_index_mean_value = df['search_index'].mean(axis=0)\n",
    "\n",
    "    sector_score_std_value = df['sector_score'].std()\n",
    "    search_index_std_value = df['search_index'].std()\n",
    "\n",
    "    x['sector_score']=(df['sector_score']-sector_score_mean_value)/sector_score_std_value\n",
    "    x['search_index'] = (df['search_index'] - search_index_mean_value) / search_index_std_value\n",
    "    \n",
    "    df=x\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a82c845-6afe-43a1-820a-ae8b4e8fb2ab",
   "metadata": {},
   "source": [
    "# 5. 数据切分训练集与测试集"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6911e7",
   "metadata": {},
   "source": [
    "## 5.1 数据切分函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07835973",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(train_num=train_num,wenben_back=wenben_back):\n",
    "    \n",
    "    # 先切分\n",
    "    daily_train_df=daily_df.loc[daily_df.index<train_num]\n",
    "    daily_test_df=daily_df.loc[daily_df.index>=train_num]\n",
    "    \n",
    "    fif_train_df=fif_df.loc[fif_df.index<16*train_num]\n",
    "    fif_test_df=fif_df.loc[fif_df.index>=16*train_num]\n",
    "    \n",
    "    wenben_train_df=wenben_df.loc[wenben_df.index<train_num]\n",
    "    wenben_test_df=wenben_df.loc[wenben_df.index>=train_num]\n",
    "\n",
    "    target_train_df=target_df.loc[target_df.index<train_num]\n",
    "    target_test_df=target_df.loc[target_df.index>=train_num]\n",
    "\n",
    "    \n",
    "    #再进行归一化\n",
    "    daily_train_df=norm(daily_train_df)\n",
    "    daily_test_df=norm(daily_test_df)\n",
    "    fif_train_df=norm(fif_train_df)\n",
    "    fif_test_df=norm(fif_test_df)\n",
    "    wenben_train_df=wenben_norm(wenben_train_df)\n",
    "    wenben_test_df = wenben_norm(wenben_test_df)\n",
    "\n",
    "\n",
    "    return {'daily_train_df':daily_train_df,\n",
    "            'daily_test_df':daily_test_df,\n",
    "            'fif_train_df':fif_train_df,\n",
    "            'fif_test_df':fif_test_df,\n",
    "            'target_train_df':target_train_df,\n",
    "            'target_test_df':target_test_df,\n",
    "            'wenben_train_df':wenben_train_df,\n",
    "            'wenben_test_df': wenben_test_df\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557c115f",
   "metadata": {},
   "source": [
    "## 5.2 进行数据切分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b87cec91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "日频训练切分： (1295, 8)\n",
      "日频测试切分： (864, 8)\n",
      "十五分钟频训练切分： (20720, 6)\n",
      "十五分钟频测试切分： (14000, 6)\n",
      "训练目标切分： (1295, 2)\n",
      "测试目标切分： (875, 2)\n"
     ]
    }
   ],
   "source": [
    "daily_norm_train_df=split_data()['daily_train_df']\n",
    "print('日频训练切分：',daily_norm_train_df.shape)\n",
    "daily_norm_test_df=split_data()['daily_test_df']\n",
    "print('日频测试切分：',daily_norm_test_df.shape)\n",
    "fif_norm_train_df=split_data()['fif_train_df']\n",
    "print('十五分钟频训练切分：',fif_norm_train_df.shape)\n",
    "fif_norm_test_df=split_data()['fif_test_df']\n",
    "print('十五分钟频测试切分：',fif_norm_test_df.shape)\n",
    "target_norm_train_df=split_data()['target_train_df']\n",
    "print('训练目标切分：',target_norm_train_df.shape)\n",
    "target_norm_test_df=split_data()['target_test_df']\n",
    "print('测试目标切分：',target_norm_test_df.shape)\n",
    "wenben_norm_train_df=split_data()['wenben_train_df']\n",
    "wenben_norm_test_df=split_data()['wenben_test_df']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a225c99c-5d81-4930-8aa6-eda77400170e",
   "metadata": {},
   "source": [
    "# 6. 数据转化为神经网络输入格式"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffb3f1f-314a-4710-b96a-62d39be82ec6",
   "metadata": {},
   "source": [
    "## 6.1 建立转化类（返回多个字典）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de355a30-733f-4c79-978d-600334ad64dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data_maker:\n",
    "    def __init__(self,train_num,test_num,fif_back,daily_back,wenben_back):\n",
    "        self.train_num=train_num\n",
    "        self.test_num=test_num\n",
    "        self.fif_back=fif_back\n",
    "        self.daily_back=daily_back\n",
    "        self.wenben_back = wenben_back\n",
    "\n",
    "\n",
    "    def daily_train_data(self,data):\n",
    "        while True:\n",
    "            rows = list(range(self.train_num - self.daily_back)) #总共1650个数据，由于扣除前面20个数据，所以为1630\n",
    "            ### 先构造空（预测日长度*日后移）array\n",
    "            samples = np.zeros((len(rows),\n",
    "                                 self.daily_back,\n",
    "                                 5))\n",
    "            print(samples.shape)\n",
    "            for j in rows:\n",
    "                ### 每一个填入用于预测一天的开盘价到波动率矩阵\n",
    "                samples[j] = data.loc[\n",
    "                                  (data.index >= j) & (data.index < self.daily_back + j),\n",
    "                                  'open':'volume_rate']\n",
    "            print(data.index)\n",
    "            print('日频训练array：',samples.shape)\n",
    "            return samples\n",
    "    def fif_train_data(self,data):\n",
    "        while True:\n",
    "            rows = list(range(self.train_num - self.daily_back))\n",
    "            samples = np.zeros((len(rows),\n",
    "                                 self.fif_back,\n",
    "                                 5))\n",
    "            for j in rows:\n",
    "\n",
    "                samples[j] = data.loc[\n",
    "                              (data.index >= j * self.fif_back ) & (data.index < (j+1) * self.fif_back),\n",
    "                              'open':]\n",
    "            print('十五分钟训练array：',samples.shape)\n",
    "            return samples\n",
    "    def wenben_train_data(self,data):\n",
    "        while True:\n",
    "            rows = list(range(self.train_num - self.daily_back)) #总共1489个数据，由于扣除前面20个数据，所以为1469\n",
    "            samples = np.zeros((len(rows),\n",
    "                                 self.wenben_back,\n",
    "                                 wenben_sort))\n",
    "            for j in rows:\n",
    "\n",
    "                samples[j] = data.loc[\n",
    "                                  (data.index >= j) & (data.index < self.wenben_back + j),\n",
    "                                  first_columns:]\n",
    "            print('文本长期训练array：',samples.shape)\n",
    "            return samples\n",
    "   \n",
    "\n",
    "    def daily_test_data(self,data):\n",
    "        while True:\n",
    "            rows = list(range(self.test_num - self.daily_back))\n",
    "            print(self.test_num,self.daily_back)\n",
    "            print(rows)\n",
    "            samples = np.zeros((len(rows),\n",
    "                                self.daily_back,\n",
    "                                 5))\n",
    "            for j in rows:\n",
    "\n",
    "\n",
    "                samples[j] = data.loc[\n",
    "                                  (data.index >= self.train_num+j) & (data.index < self.train_num+self.daily_back + j),\n",
    "                                  'open':'volume_rate']\n",
    "            print('日测试array：',samples.shape)\n",
    "            print('试一试index', data.index,'train_num',self.train_num)\n",
    "            return samples\n",
    "\n",
    "    def wenben_test_data(self, data):\n",
    "        while True:\n",
    "            rows = list(range(self.test_num - self.daily_back))\n",
    "            samples = np.zeros((len(rows),\n",
    "                                self.wenben_back,\n",
    "                                wenben_sort))\n",
    "            for j in rows:\n",
    "                samples[j] = data.loc[\n",
    "                             (data.index >= self.train_num + j) & (data.index < self.train_num + self.wenben_back + j),\n",
    "                             first_columns:]\n",
    "            print('长期文本测试array：', samples.shape)\n",
    "            return samples\n",
    "   \n",
    "    def fif_test_data(self,data):\n",
    "        while True:\n",
    "            rows = list(range(self.test_num - self.daily_back))\n",
    "            samples = np.zeros((len(rows),\n",
    "                                self.fif_back,\n",
    "                                 5))\n",
    "            for j in rows:\n",
    "\n",
    "\n",
    "                samples[j] = data.loc[\n",
    "                                 (data.index >= 16*self.train_num+(j) * self.fif_back) & (data.index < 16*self.train_num+(j+1) * self.fif_back),\n",
    "                                 'open':]\n",
    "            print('十五分钟测试array：',samples.shape)\n",
    "            return samples\n",
    "    def target_train_data(self,data):\n",
    "        while True:\n",
    "            rows = list(range(self.train_num-self.daily_back))\n",
    "            targets = np.zeros((len(rows),))\n",
    "            for j in rows:\n",
    "\n",
    "\n",
    "                targets[j] = data.loc[data.index == j, 'target'].iloc[0] #根据提示，添加了.iloc[0]\n",
    "            print('训练标签array',targets.shape)\n",
    "            return targets\n",
    "    def target_test_data(self,data):\n",
    "        while True:\n",
    "            rows = list(range(self.test_num-self.daily_back))\n",
    "            targets = np.zeros((len(rows),))\n",
    "            for j in rows:\n",
    "\n",
    "\n",
    "                targets[j] = data.loc[data.index == self.train_num+j, 'target'].iloc[0] ##出问题：应该是。而不是***：data.index == self.train_num+j\n",
    "            print(targets.shape)\n",
    "            return targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d109eb0-7de5-414a-a276-f81fcefe1269",
   "metadata": {},
   "source": [
    "## 6.2 设置类方法里的参数，赋值给origin_data_maker，仍然是一个class类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e39a13e8-0b0d-4cb8-b630-a142d4529615",
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_data_maker=Data_maker(train_num=train_num,test_num=test_num,fif_back=16,daily_back=daily_back,wenben_back=wenben_back)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84200b8",
   "metadata": {},
   "source": [
    "# 6.3 调用类中的方法,处理原始数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a26f72f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1275, 20, 5)\n",
      "Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,\n",
      "       ...\n",
      "       1285, 1286, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1294],\n",
      "      dtype='int64', length=1295)\n",
      "日频训练array： (1275, 20, 5)\n",
      "864 20\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843]\n",
      "日测试array： (844, 20, 5)\n",
      "试一试index Index([1295, 1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1304,\n",
      "       ...\n",
      "       2149, 2150, 2151, 2152, 2153, 2154, 2155, 2156, 2157, 2158],\n",
      "      dtype='int64', length=864) train_num 1295\n",
      "十五分钟训练array： (1275, 16, 5)\n",
      "十五分钟测试array： (844, 16, 5)\n",
      "文本长期训练array： (1275, 10, 2)\n",
      "长期文本测试array： (844, 10, 2)\n",
      "训练标签array (1275,)\n",
      "(844,)\n"
     ]
    }
   ],
   "source": [
    "DM = origin_data_maker\n",
    "\n",
    "daily_train_prepared = DM.daily_train_data(daily_norm_train_df)\n",
    "daily_test_prepared = DM.daily_test_data(daily_norm_test_df)\n",
    "\n",
    "fif_train_prepared = DM.fif_train_data(fif_norm_train_df)\n",
    "fif_test_prepared = DM.fif_test_data(fif_norm_test_df)\n",
    "\n",
    "wenben_train_prepared = DM.wenben_train_data(wenben_norm_train_df)\n",
    "wenben_test_prepared = DM.wenben_test_data(wenben_norm_test_df)\n",
    "\n",
    "target_train_prepared = DM.target_train_data(target_norm_train_df)\n",
    "target_test_prepared = DM.target_test_data(target_norm_test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "082f7ca9-9c73-4357-95e4-b0639fc865cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# daily_train_prepared\n",
    "# daily_test_prepared\n",
    "\n",
    "# fif_train_prepared\n",
    "# fif_test_prepared \n",
    "\n",
    "# wenben_train_prepared\n",
    "# wenben_test_prepared\n",
    "\n",
    "# target_train_prepared\n",
    "# target_test_prepared"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb802e8a",
   "metadata": {},
   "source": [
    "# 7. 神经网络模型训练"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9ca801-990d-4205-a794-e3784edf76a1",
   "metadata": {},
   "source": [
    "## 7.1 模型建立 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f40a1c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def my_model(daily_back, LSTM_num, dense_num, learning_rate):\n",
    "    # 15分钟频输入\n",
    "    fif_min_input = Input(shape=(16, 5), dtype='float32', name='fif_min_input')\n",
    "    Conv1D_fif = layers.Conv1D(16, 1, strides=1)(fif_min_input)\n",
    "    LSTM_fif = layers.LSTM(LSTM_num)(Conv1D_fif)\n",
    "    \n",
    "    # 日频输入\n",
    "    daily_input = Input(shape=(daily_back, 5), dtype='float32', name='daily_input')\n",
    "    Conv1D_daily = layers.Conv1D(16, 1, strides=1)(daily_input)\n",
    "    LSTM_daily = layers.LSTM(LSTM_num)(Conv1D_daily)\n",
    "    \n",
    "    # 合并与全连接\n",
    "    concatenated = layers.concatenate([LSTM_fif, LSTM_daily], axis=-1)\n",
    "    alloy = layers.Dense(dense_num, activation='relu')(concatenated)\n",
    "    dropout = layers.Dropout(0.2)(alloy)\n",
    "    output = layers.Dense(1, activation='sigmoid')(dropout)\n",
    "    \n",
    "    model = Model([fif_min_input, daily_input], output)\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), \n",
    "                  loss='binary_crossentropy', \n",
    "                  metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cb0845-d365-4979-84d5-90540b299960",
   "metadata": {},
   "source": [
    "# 2. 定义适应度函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8dbc63ea-2505-488f-adc7-0a778f7879a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def fitness_function(params):\n",
    "    LSTM_num = int(params[0])\n",
    "    dense_num = int(params[1])\n",
    "    learning_rate = params[2]\n",
    "    \n",
    "    model = my_model(daily_back=daily_back,  # 替换为实际daily_back值\n",
    "                     LSTM_num=LSTM_num,\n",
    "                     dense_num=dense_num,\n",
    "                     learning_rate=learning_rate)\n",
    "    \n",
    "    history = model.fit(x=[fif_train_prepared,daily_train_prepared],y=target_train_prepared,batch_size=batch_size,\n",
    "                validation_split=0.25,epochs=epochs)\n",
    "    return history.history['val_loss'][-1]  # 返回验证损失（越小越好）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcb4aca-acf5-42c1-a3e3-a0146a1b4310",
   "metadata": {},
   "source": [
    "# 3. 实现麻雀搜索算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ffb38a63-5310-43c4-b7b7-6181f62e545f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparrow(pop_size, max_iter, dim, lower_bounds, upper_bounds, fitness_func):\n",
    "    pop = np.random.uniform(low=lower_bounds, high=upper_bounds, size=(pop_size, dim))\n",
    "    fitness = np.array([fitness_func(ind) for ind in pop])\n",
    "    best_idx = np.argmin(fitness)\n",
    "    best_sol = pop[best_idx].copy()\n",
    "    best_fit = fitness[best_idx]\n",
    "\n",
    "    for t in range(max_iter):\n",
    "        # 排序\n",
    "        sorted_idx = np.argsort(fitness)\n",
    "        pop = pop[sorted_idx]\n",
    "        fitness = fitness[sorted_idx]\n",
    "\n",
    "        # 发现者策略\n",
    "        for i in range(int(pop_size * 0.2)):\n",
    "            if np.random.rand() < 0.8:\n",
    "                pop[i] *= np.exp(-i / (np.random.rand() * max_iter))\n",
    "            else:\n",
    "                pop[i] += np.random.normal(0, 1)\n",
    "            \n",
    "            # 每次更新后立即检查边界\n",
    "            pop[i] = np.clip(pop[i], lower_bounds, upper_bounds)\n",
    "\n",
    "        # 跟随者策略 - 改进矩阵计算\n",
    "        for i in range(int(pop_size * 0.2), pop_size):\n",
    "            if i > pop_size / 2:\n",
    "                pop[i] = np.random.normal(0, 1) * np.exp((pop[-1] - pop[i]) / (i ** 2))\n",
    "            else:\n",
    "                # 简化矩阵计算，避免奇异矩阵问题\n",
    "                A = np.random.choice([-1, 1], size=dim)\n",
    "                pop[i] = pop[0] + A * (pop[0] - pop[i])\n",
    "            \n",
    "            # 每次更新后立即检查边界\n",
    "            pop[i] = np.clip(pop[i], lower_bounds, upper_bounds)\n",
    "\n",
    "        # 警戒者策略\n",
    "        for i in range(pop_size):\n",
    "            if fitness[i] > best_fit:\n",
    "                pop[i] = best_sol + np.random.normal(0, 1)\n",
    "                # 立即检查边界\n",
    "                pop[i] = np.clip(pop[i], lower_bounds, upper_bounds)\n",
    "\n",
    "        # 更新最佳解\n",
    "        fitness = np.array([fitness_func(ind) for ind in pop])\n",
    "        current_best_idx = np.argmin(fitness)\n",
    "        if fitness[current_best_idx] < best_fit:\n",
    "            best_fit = fitness[current_best_idx]\n",
    "            best_sol = pop[current_best_idx].copy()\n",
    "\n",
    "    return best_sol, best_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a102678-07e2-469d-9ec9-d9e8ca85b71a",
   "metadata": {},
   "source": [
    "# 4. 运行优化并训练最终模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fdda013f-3939-4290-af12-48381f4273d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - acc: 0.4877 - loss: 0.7504 - val_acc: 0.5423 - val_loss: 0.7342\n",
      "Epoch 2/10\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - acc: 0.5458 - loss: 0.6921 - val_acc: 0.5047 - val_loss: 0.6951\n",
      "Epoch 3/10\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - acc: 0.4687 - loss: 0.6987 - val_acc: 0.5423 - val_loss: 0.6903\n",
      "Epoch 4/10\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - acc: 0.5243 - loss: 0.6893 - val_acc: 0.5423 - val_loss: 0.7034\n",
      "Epoch 5/10\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - acc: 0.5427 - loss: 0.6824 - val_acc: 0.5423 - val_loss: 0.7044\n",
      "Epoch 6/10\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - acc: 0.5326 - loss: 0.6786 - val_acc: 0.4984 - val_loss: 0.7042\n",
      "Epoch 7/10\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - acc: 0.5025 - loss: 0.7116 - val_acc: 0.4671 - val_loss: 0.7288\n",
      "Epoch 8/10\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - acc: 0.5596 - loss: 0.6930 - val_acc: 0.5486 - val_loss: 0.6847\n",
      "Epoch 9/10\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - acc: 0.4934 - loss: 0.6941 - val_acc: 0.5078 - val_loss: 0.9450\n",
      "Epoch 10/10\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - acc: 0.5173 - loss: 0.6989 - val_acc: 0.5423 - val_loss: 0.7030\n",
      "Epoch 1/10\n",
      "\u001b[1m25/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - acc: 0.5242 - loss: 0.7068"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m pop_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m      5\u001b[0m max_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[0;32m----> 7\u001b[0m best_params, best_fitness \u001b[38;5;241m=\u001b[39m\u001b[43msparrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpop_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlower_bounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupper_bounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfitness_function\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m最佳参数：LSTM_num=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mint\u001b[39m(best_params[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, dense_num=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mint\u001b[39m(best_params[\u001b[38;5;241m1\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, learning_rate=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_params[\u001b[38;5;241m2\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m最佳验证准确率：\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_fitness\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[14], line 3\u001b[0m, in \u001b[0;36msparrow\u001b[0;34m(pop_size, max_iter, dim, lower_bounds, upper_bounds, fitness_func)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msparrow\u001b[39m(pop_size, max_iter, dim, lower_bounds, upper_bounds, fitness_func):\n\u001b[1;32m      2\u001b[0m     pop \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39muniform(low\u001b[38;5;241m=\u001b[39mlower_bounds, high\u001b[38;5;241m=\u001b[39mupper_bounds, size\u001b[38;5;241m=\u001b[39m(pop_size, dim))\n\u001b[0;32m----> 3\u001b[0m     fitness \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([fitness_func(ind) \u001b[38;5;28;01mfor\u001b[39;00m ind \u001b[38;5;129;01min\u001b[39;00m pop])\n\u001b[1;32m      4\u001b[0m     best_idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmin(fitness)\n\u001b[1;32m      5\u001b[0m     best_sol \u001b[38;5;241m=\u001b[39m pop[best_idx]\u001b[38;5;241m.\u001b[39mcopy()\n",
      "Cell \u001b[0;32mIn[14], line 3\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msparrow\u001b[39m(pop_size, max_iter, dim, lower_bounds, upper_bounds, fitness_func):\n\u001b[1;32m      2\u001b[0m     pop \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39muniform(low\u001b[38;5;241m=\u001b[39mlower_bounds, high\u001b[38;5;241m=\u001b[39mupper_bounds, size\u001b[38;5;241m=\u001b[39m(pop_size, dim))\n\u001b[0;32m----> 3\u001b[0m     fitness \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[43mfitness_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mind\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m ind \u001b[38;5;129;01min\u001b[39;00m pop])\n\u001b[1;32m      4\u001b[0m     best_idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmin(fitness)\n\u001b[1;32m      5\u001b[0m     best_sol \u001b[38;5;241m=\u001b[39m pop[best_idx]\u001b[38;5;241m.\u001b[39mcopy()\n",
      "Cell \u001b[0;32mIn[13], line 13\u001b[0m, in \u001b[0;36mfitness_function\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m      6\u001b[0m learning_rate \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m      8\u001b[0m model \u001b[38;5;241m=\u001b[39m my_model(daily_back\u001b[38;5;241m=\u001b[39mdaily_back,  \u001b[38;5;66;03m# 替换为实际daily_back值\u001b[39;00m\n\u001b[1;32m      9\u001b[0m                  LSTM_num\u001b[38;5;241m=\u001b[39mLSTM_num,\n\u001b[1;32m     10\u001b[0m                  dense_num\u001b[38;5;241m=\u001b[39mdense_num,\n\u001b[1;32m     11\u001b[0m                  learning_rate\u001b[38;5;241m=\u001b[39mlearning_rate)\n\u001b[0;32m---> 13\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mfif_train_prepared\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdaily_train_prepared\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_train_prepared\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.25\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/miniforge3/envs/tf_env/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniforge3/envs/tf_env/lib/python3.9/site-packages/keras/src/backend/tensorflow/trainer.py:371\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[1;32m    370\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 371\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    372\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m~/miniforge3/envs/tf_env/lib/python3.9/site-packages/keras/src/backend/tensorflow/trainer.py:219\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfunction\u001b[39m(iterator):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    217\u001b[0m         iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[1;32m    218\u001b[0m     ):\n\u001b[0;32m--> 219\u001b[0m         opt_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[1;32m    221\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/tf_env/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniforge3/envs/tf_env/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniforge3/envs/tf_env/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/tf_env/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/tf_env/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniforge3/envs/tf_env/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/miniforge3/envs/tf_env/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/miniforge3/envs/tf_env/lib/python3.9/site-packages/tensorflow/python/eager/context.py:1552\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1550\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1552\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1553\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1554\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1555\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1556\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1557\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1558\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1560\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1561\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1562\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1566\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1567\u001b[0m   )\n",
      "File \u001b[0;32m~/miniforge3/envs/tf_env/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 超参数范围（LSTM_num, dense_num, learning_rate）\n",
    "lower_bounds = [64, 16, 1e-4]\n",
    "upper_bounds = [256, 64, 1e-2]\n",
    "pop_size = 10\n",
    "max_iter = 5\n",
    "\n",
    "best_params, best_fitness =sparrow(pop_size, max_iter, 3, lower_bounds, upper_bounds, fitness_function)\n",
    "\n",
    "print(f\"最佳参数：LSTM_num={int(best_params[0])}, dense_num={int(best_params[1])}, learning_rate={best_params[2]}\")\n",
    "print(f\"最佳验证准确率：{best_fitness}\")\n",
    "\n",
    "# 用最佳参数训练最终模型\n",
    "final_model = my_model(daily_back=daily_back,  # 替换为实际值\n",
    "                       LSTM_num=int(best_params[0]),\n",
    "                       dense_num=int(best_params[1]),\n",
    "                       learning_rate=best_params[2])\n",
    "final_model.fit(x=[fif_train_prepared,daily_train_prepared],y=target_train_prepared,batch_size=batch_size,\n",
    "                validation_split=0.25,epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a065f8c",
   "metadata": {},
   "source": [
    "## 7.2 模型滞后时长赋值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993a90eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model=my_model(daily_back=daily_back)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e025ba5e-a33c-4474-9138-18ad1474565b",
   "metadata": {},
   "source": [
    "## 7.3 添加输出模型参数的代码块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42bfef1-b9f0-4103-9a4d-c90f8bb13126",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(final_model, to_file='model_structure.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8620eccf",
   "metadata": {},
   "source": [
    "## 7.4 model.fit(输入训练数据x，标志y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebf83ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = final_model.fit(x=[fif_train_prepared,daily_train_prepared],y=target_train_prepared,batch_size=batch_size,validation_split=0.25,epochs=epochs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd0ae96",
   "metadata": {},
   "source": [
    "## 7.5 model.evaluate(输入测试数据)，进行模型预测性能测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bd90e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss,accuracy = final_model.evaluate([fif_test_prepared,daily_test_prepared],y=target_test_prepared)\n",
    "print(loss,accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62e60b0-7dc9-47e4-b131-df7a159dbf01",
   "metadata": {},
   "source": [
    "# 8. 回测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9607cca",
   "metadata": {},
   "source": [
    "# 构建y的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc23d49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_y_pred():\n",
    "    y_predict=final_model.predict([fif_test_prepared,daily_test_prepared],batch_size=1).reshape(test_num-daily_back).tolist() ###batch_size要设为1，不然evaluate和predict结果不同\n",
    "    y_pred=[]\n",
    "    for i,v in enumerate(y_predict):\n",
    "        if v>0.5:\n",
    "            y_pred.append(1)\n",
    "        if v<0.5:\n",
    "            y_pred.append(0)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915e4535",
   "metadata": {},
   "source": [
    "# 制作y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191b4fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=gen_y_pred()\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0f800a",
   "metadata": {},
   "source": [
    "#  构建使用测试集作为回测数据的类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c753f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Back_tes_trader:\n",
    "    def __init__(self,train_num,daily_back):\n",
    "        self.train_num=train_num\n",
    "        self.daily_back=daily_back\n",
    "    def daily_test_data(self,data):\n",
    "        while True:\n",
    "            samples = data.loc[\n",
    "                data.index >=self.train_num+self.daily_back ,\n",
    "                ['open','close']]\n",
    "            print(data.index)\n",
    "            return samples\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8bb8f4",
   "metadata": {},
   "source": [
    "# 回测数据集代入参数，形成回撤数据back_tes_trader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9555c139",
   "metadata": {},
   "outputs": [],
   "source": [
    "back_tes_trader=Back_tes_trader(train_num=train_num,daily_back=daily_back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b72e4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_back_trader(train_num=train_num):\n",
    "\n",
    "    daily_test_df=daily_df.loc[daily_df.index>=train_num]\n",
    "\n",
    "    return {'daily_test_df':daily_test_df}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0caaf456",
   "metadata": {},
   "outputs": [],
   "source": [
    "back_df=split_back_trader()['daily_test_df']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff686572",
   "metadata": {},
   "outputs": [],
   "source": [
    "back_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd75b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "backtrader_df=back_tes_trader.daily_test_data(back_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8c3651",
   "metadata": {},
   "source": [
    "# 形成day_rate_of_return日内收益率，和rate_of_return隔夜收益率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84028e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "backtrader_df['rate_of_return'] = backtrader_df['close'].rolling(2).apply(lambda x: x[1] / x[0] - 1, raw=True)\n",
    "backtrader_df['day_rate_of_return']=backtrader_df['close']/backtrader_df['open']-1\n",
    "\n",
    "clo_1=backtrader_df.loc[(backtrader_df.index<total_day-1),\"close\"].tolist()\n",
    "\n",
    "print(len(clo_1))\n",
    "print(backtrader_df.loc[(backtrader_df.index>=train_num+daily_back+1),:])\n",
    "backtrader_df.loc[(backtrader_df.index>=train_num+daily_back+1),'last_close']=clo_1\n",
    "backtrader_df['sale_rate_of_return']=backtrader_df['open']/backtrader_df['last_close']-1\n",
    "\n",
    "\n",
    "print(backtrader_df)\n",
    "print(backtrader_df.shape)\n",
    "trade_day_return_list=[]\n",
    "return_list=[]\n",
    "every_day_return_list=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94506474",
   "metadata": {},
   "source": [
    "# 回测交易逻辑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2a5071",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtrader(list,df):\n",
    "    a=0\n",
    "\n",
    "    rate_of_return = 1\n",
    "    for i,v in enumerate(list):\n",
    "        if (v ==1)&(a==0):\n",
    "            b=(1 + df.loc[train_num+daily_back + i, 'day_rate_of_return'])\n",
    "            rate_of_return= rate_of_return * b\n",
    "            a=1\n",
    "            trade_day_return_list.append(b-1)\n",
    "            return_list.append(rate_of_return)\n",
    "            every_day_return_list.append(b - 1)\n",
    "\n",
    "        elif (v ==1)&(a==1):\n",
    "            b=(1 + df.loc[train_num+daily_back + i, 'rate_of_return'])\n",
    "            rate_of_return= rate_of_return *b\n",
    "            a=a\n",
    "            trade_day_return_list.append(b-1)\n",
    "            return_list.append(rate_of_return)\n",
    "            every_day_return_list.append(b - 1)\n",
    "        elif (v==0)&(a==0):\n",
    "            rate_of_return=rate_of_return\n",
    "            a=a\n",
    "            every_day_return_list.append(0)\n",
    "\n",
    "        elif (v==0)&(a==1):\n",
    "            a=0\n",
    "            b = (1 + df.loc[train_num+daily_back + i, 'sale_rate_of_return'])\n",
    "            rate_of_return=rate_of_return*b\n",
    "            trade_day_return_list.append(b-1)\n",
    "            every_day_return_list.append(b - 1)\n",
    "            return_list.append(rate_of_return)\n",
    "    return a,trade_day_return_list,rate_of_return,return_list,every_day_return_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a6e92b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eda96a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "result=backtrader(y_pred,backtrader_df)\n",
    "# print(result[1])\n",
    "# print(result[2])\n",
    "# print(result[3])\n",
    "pingjun_nian_jiaoyi_ri=240*len(result[1])/(len(y_pred))\n",
    "sharp=(np.mean(result[1]))/(np.std(result[1],ddof=1))*np.sqrt(pingjun_nian_jiaoyi_ri)\n",
    "# sharp1=(np.mean(result[4]))/(np.std(result[4]))\n",
    "# print('夏普比率--：',sharp1)\n",
    "print('夏普比率：',sharp)\n",
    "print('收益率：',result[2]-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2ded5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e894d8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "returns=result[3]\n",
    "returns = [ret - 1 for ret in returns]\n",
    "# returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c359f589",
   "metadata": {},
   "outputs": [],
   "source": [
    "returns=result[3]\n",
    "returns = [ret - 1 for ret in returns]\n",
    "\n",
    "# 将收益率列表转换为pandas的Series对象，方便处理\n",
    "returns_series = pd.Series(returns)\n",
    "\n",
    "# 计算累计收益率\n",
    "cumulative_returns = (1 + returns_series).cumprod() - 1\n",
    "\n",
    "# 计算滚动最大值\n",
    "rolling_max = cumulative_returns.cummax()\n",
    "\n",
    "# 计算回撤\n",
    "drawdown = cumulative_returns - rolling_max\n",
    "\n",
    "# 计算最大回撤\n",
    "max_drawdown = drawdown.min()\n",
    "\n",
    "# 打印最大回撤\n",
    "print(\"最大回撤: {:.2%}\".format(max_drawdown))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d346e244",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb03bdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def paint():\n",
    "    acc=history.history['acc']\n",
    "    val_acc=history.history['val_acc']\n",
    "    loss=history.history['loss']\n",
    "    val_loss=history.history['val_loss']\n",
    "\n",
    "    epochs=range(len(acc))\n",
    "    plt.plot(epochs,acc,'bo',label='Training acc')\n",
    "    plt.plot(epochs,val_acc,'b',label='Validation acc')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.figure()\n",
    "\n",
    "    plt.plot(epochs,loss,'bo',label='Training loss')\n",
    "    plt.plot(epochs,val_loss,'b',label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()\n",
    "    return plt\n",
    "my_paint=paint()\n",
    "my_paint.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff449cf1",
   "metadata": {},
   "source": [
    "# 混淆矩阵绘制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2eaf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = confusion_matrix(target_test_prepared, y_pred,labels=[1,0])\n",
    "precision_score=precision_score(target_test_prepared, y_pred)\n",
    "recall_score=recall_score(target_test_prepared, y_pred)\n",
    "f1_score=f1_score(target_test_prepared, y_pred)\n",
    "\n",
    "print('混淆矩阵：',confusion_matrix)\n",
    "print('查准率：',precision_score)\n",
    "print('查全率：',recall_score)\n",
    "print('f1-score:',f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52941452",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict=final_model.predict([fif_test_prepared,daily_test_prepared]).reshape(test_num-daily_back).tolist()\n",
    "fpr,tpr,threshold = roc_curve(target_test_prepared, y_predict) ###计算真正率和假正率\n",
    "# print(fpr,tpr,threshold)\n",
    "roc_auc = auc(fpr,tpr)\n",
    "\n",
    "\n",
    "lw = 2\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc) ###假正率为横坐标，真正率为纵坐标做曲线\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302466a8",
   "metadata": {},
   "source": [
    "# 保存"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "tf_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
